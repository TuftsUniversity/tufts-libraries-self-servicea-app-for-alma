
2025-04-30T13:48:46.719976
================================ System Message ================================

You will get instructions for code to write.
You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.
Think step by step and reason yourself to the correct decisions to make sure we get it right.
Make changes to existing code and implement new code in the unified git diff syntax. When implementing new code, First lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.

You will output the content of each file necessary to achieve the goal, including ALL code.
Output requested code changes and new code in the unified "git diff" syntax. Example:

```diff
--- example.txt
+++ example.txt
@@ -6,3 +6,4 @@
     line content A
     line content B
+    new line added
-    original line X
+    modified line X with changes
@@ -26,4 +27,5 @@
         condition check:
-            action for condition A
+            if certain condition is met:
+                alternative action for condition A
         another condition check:
-            action for condition B
+            modified action for condition B
```

Example of a git diff creating a new file:

```diff
--- /dev/null
+++ new_file.txt
@@ -0,0 +1,3 @@
+First example line
+
+Last example line
```

RULES:
-A program will apply the diffs you generate exactly to the code, so diffs must be precise and unambiguous!
-Every diff must be fenced with triple backtick ```.
-The file names at the beginning of a diff, (lines starting with --- and +++) is the relative path to the file before and after the diff.
-LINES TO BE REMOVED (starting with single -) AND LINES TO BE RETAIN (no starting symbol) HAVE TO REPLICATE THE DIFFED HUNK OF THE CODE EXACTLY LINE BY LINE. KEEP THE NUMBER OF RETAIN LINES SMALL IF POSSIBLE.
-EACH LINE IN THE SOURCE FILES STARTS WITH A LINE NUMBER, WHICH IS NOT PART OF THE SOURCE CODE. NEVER TRANSFER THESE LINE NUMBERS TO THE DIFF HUNKS.
-AVOID STARTING A HUNK WITH AN EMPTY LINE.
-ENSURE ALL CHANGES ARE PROVIDED IN A SINGLE DIFF CHUNK PER FILE TO PREVENT MULTIPLE DIFFS ON THE SAME FILE.


As far as compatible with the user request, start with the "entrypoint" file, then go to the ones that are imported by that file, and so on.
Please note that the code should be fully functional. No placeholders.

Follow a language and framework appropriate best practice file naming convention.
Make sure that files contain all imports, types etc.  The code should be fully functional. Make sure that code in different files are compatible with each other.
Ensure to implement all code, if you are unsure, write a plausible implementation.
Include module dependency or package manager dependency definition file.
Before you finish, double check that all parts of the architecture is present in the files.

When you are done, write finish with "this concludes a fully working implementation".

Useful to know:
Almost always put different classes in different files.
Always use the programming language the user asks for.
For Python, you always create an appropriate requirements.txt file.
For NodeJS, you always create an appropriate package.json file.
Always add a comment briefly describing the purpose of the function definition.
Add comments explaining very complex bits of logic.
Always follow the best practices for the requested languages for folder/file structure and how to package the project.


Python toolbelt preferences:
- pytest
- dataclasses


================================ Human Message =================================

```
File: app/__init__.py
1 from flask import Flask
2 from app.main import main_blueprint
3 from app.barnes_and_noble import barnes_and_noble_blueprint
4 from app.p_and_e_rollup_match import p_and_e_blueprint
5 from app.bib_2_holdings_541 import blueprint_541
6 from dotenv import load_dotenv
7 
8 
9 def create_app():
10     app = Flask(__name__)
11 
12     app.register_blueprint(main_blueprint)
13     app.register_blueprint(barnes_and_noble_blueprint, url_prefix="/barnes_and_noble")
14     app.register_blueprint(p_and_e_blueprint, url_prefix="/p_and_e")
15     app.register_blueprint(blueprint_541, url_prefix="/bib_2_holdings_541")
16 
17     load_dotenv()
18     return app
19 

File: app/app.py
1 from flask import Flask, Blueprint, render_template
2 import pandas as pd
3 import os
4 
5 # from main.routes import main_blueprint
6 # from barnes_and_noble.routes import barnes_and_noble_blueprint
7 # from p_and_e_rollup_match.routes import p_and_e_blueprint
8 
9 app = Flask(__name__)
10 
11 
12 # app.register_blueprint(main_blueprint)
13 # app.register_blueprint(barnes_and_noble_blueprint, url_prefix="/barnes_and_noble")
14 # app.register_blueprint(p_and_e_blueprint, url_prefix="/p_and_e")
15 if __name__ == "__main__":
16     app.run(debug=True)
17 

File: app/barnes_and_noble/__init__.py
1 from .routes import barnes_and_noble_blueprint
2 

File: app/barnes_and_noble/barnes_and_noble.py
1 import os
2 import pandas as pd
3 import requests
4 import json
5 import re
6 from flask import current_app
7 from werkzeug.utils import secure_filename
8 
9 
10 class OverlapAnalysis:
11     def __init__(self, file_path):
12         self.file_path = file_path
13 
14     def process(self):
15         # Load the Excel file
16         df_input = pd.read_excel(self.file_path, dtype=str, engine="openpyxl")
17         df_input["course_code"] = ""
18         df_input["section"] = ""
19         df_input["course_name"] = ""
20         df_input["processing_department"] = ""
21         df = df_input.copy()
22 
23         for column in df.columns:
24             df[column] = df[column].astype(str)
25             df[column] = df[column].apply(lambda x: x.replace('"', ""))
26 
27         # Process each row
28         for index, row in df.iterrows():
29             semester = row["Term"]
30             if "F" in semester:
31                 semester = semester.replace("F", "Fa")
32             elif "W" in semester:
33                 semester = semester.replace("W", "Sp")
34 
35             course = row["Course"]
36             section = row["Sec"]
37 
38             # Construct request URL
39             request_url = (
40                 "https://api-na.hosted.exlibrisgroup.com/almaws/v1/courses?"
41                 + "apikey="
42                 + secrets_local.prod_courses_api_key
43                 + "&q=name~"
44                 + semester
45                 + "*"
46                 + row["Dept"]
47                 + "*"
48                 + row["Course"]
49                 + "*"
50                 + row["Sec"]
51                 + "&format=json"
52             )
53 
54             response = requests.get(request_url).json()
55 
56             if int(response["total_record_count"]) > 1:
57                 for course in response["course"]:
58                     course_name = course["name"]
59                     result = bool(
60                         re.match(
61                             rf"^{semester}-[0\s]*{row['Dept']}\s*-[0\s]*{row['Course']}\s*-[0\s]*{row['Sec']}.+",
62                             course_name,
63                         )
64                     )
65                     if result:
66                         correct_course = course
67                         break
68             else:
69                 correct_course = response.get("course", [{}])[0]
70 
71             df.loc[index, "course_code"] = correct_course.get(
72                 "code", "Error finding course"
73             )
74             df.loc[index, "section"] = correct_course.get(
75                 "section", "Error finding course"
76             )
77             df.loc[index, "course_name"] = correct_course.get(
78                 "name", "Error finding course"
79             )
80             df.loc[index, "processing_department"] = correct_course.get(
81                 "processing_department", {}
82             ).get("desc", "Error finding processing department")
83 
84         output_path = os.path.join(
85             current_app.config["DOWNLOAD_FOLDER"], "Updated_Barnes_and_Noble.xlsx"
86         )
87         df.to_excel(output_path, index=False)
88         return output_path
89 

File: app/barnes_and_noble/requirements.txt
1 Flask==2.0.2
2 pandas==2.0.3
3 Requests==2.32.3
4 Werkzeug==2.0.3
5 

File: app/barnes_and_noble/routes.py
1 from flask import (
2     Blueprint,
3     request,
4     redirect,
5     url_for,
6     send_file,
7     current_app,
8     render_template,
9 )
10 from werkzeug.utils import secure_filename
11 import os
12 from .barnes_and_noble import OverlapAnalysis
13 
14 barnes_and_noble_blueprint = Blueprint("barnes_and_noble", __name__)
15 
16 
17 @barnes_and_noble_blueprint.route("/upload", methods=["POST"])
18 def upload_file():
19     if "file" not in request.files:
20         return redirect(url_for("main.error"))
21     file = request.files["file"]
22     if file.filename == "":
23         return redirect(url_for("main.error"))
24     filename = secure_filename(file.filename)
25     file_path = os.path.join(current_app.config["UPLOAD_FOLDER"], filename)
26     file.save(file_path)
27     analysis = OverlapAnalysis(file_path)
28     output_path = analysis.process()
29     return send_file(output_path, as_attachment=True)
30 
31 
32 @barnes_and_noble_blueprint.route("/", methods=["GET"])
33 def index():
34     return render_template("barnes_and_noble.html")
35 

File: app/bib_2_holdings_541/__init__.py
1 from .routes import blueprint_541
2 

File: app/bib_2_holdings_541/bib_2_holdings_541.py
1 import os
2 import pandas as pd
3 import re
4 from flask import (
5     Blueprint,
6     request,
7     redirect,
8     url_for,
9     send_file,
10     current_app,
11     render_template,
12 )
13 from werkzeug.utils import secure_filename
14 import io
15 from io import BytesIO
16 import zipfile
17 import dotenv
18 import os
19 from dotenv import load_dotenv
20 import json
21 import requests
22 import time
23 import pymarc as pym
24 import _elementtree as et
25 
26 
27 def zip_files(filenames):
28     memory_file = BytesIO()
29     with zipfile.ZipFile(memory_file, "w", zipfile.ZIP_DEFLATED) as zf:
30         for filename in filenames:
31             data = open(filename, "rb").read()
32             zf.writestr(os.path.basename(filename), data)
33     memory_file.seek(0)
34     return memory_file
35 
36 
37 class Bib2Holdings541:
38     def __init__(self, file_path):
39         self.file_path = file_path
40 
41         self.sandbox_bib_api_key = json.loads(os.getenv("sandbox_bib_api_key"))
42         self.analytics_api_key = json.loads(os.getenv("analytics_api_key"))
43         self.bib_url = json.loads(os.getenv("bib_url"))
44         self.errorCount = 0
45         # mismatchCount = 0
46         self.successCount = 0
47 
48         self.count_file = io.BytesIO()
49 
50         self.output_file = io.BytesIO()
51         self.output_file.write(
52             '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><holdings>'
53         )
54         self.error_file = io.BytesIO()
55 
56     def zip_files(filenames):
57         memory_file = BytesIO()
58         with zipfile.ZipFile(memory_file, "w", zipfile.ZIP_DEFLATED) as zf:
59             for filename in filenames:
60                 data = open(filename, "rb").read()
61                 zf.writestr(os.path.basename(filename), data)
62         memory_file.seek(0)
63         return memory_file
64 
65     def process(self):
66         mappings = self.getLocations()
67         bibList = []
68         bibListCounter = 0
69         with open(self.filepath, "rb") as file1:
70             for line in file1:
71                 line = line.decode("utf-8")
72                 line = line.replace("\r\n", "")
73                 bibList.append(line)
74                 bibListCounter += 1
75 
76         print("Number of bib records in input file: " + str(bibListCounter) + "\n")
77 
78         headers = {"Content-Type": "application/xml"}
79 
80         # count_file = open('Success and Error Counts.txt', 'w+')
81         # output_file = open("Output/updated_holdings.xml", "w+")
82         # output_file.write('<?xml version="1.0" encoding="UTF-8" standalone="yes"?><holdings>')
83         # error_file = open("Output/records_with_errors.txt", "w+")
84         fiveFortyOneCount = 0
85         for mms_id in bibList:
86             print("MMS ID: " + str(mms_id))
87 
88             bib_url = self.bib_url + str(mms_id) + "?apikey=" + self.sandbox_bib_api_key
89 
90             holdings_url = (
91                 self.bib_url
92                 + str(mms_id)
93                 + "/holdings?apikey="
94                 + self.sandbox_bib_api_key
95             )
96 
97             print(bib_url + "\n")
98             print("\n" + holdings_url + "\n")
99             bib_record = requests.get(bib_url)
100             bib_record_str = bib_record.content.decode("utf-8")
101             print("\nBib record: " + bib_record.text + "\n")
102             attached_holdings = requests.get(holdings_url)
103 
104             attached_holdings_str = attached_holdings.content.decode("utf-8")
105             print("\nHoldings: " + attached_holdings_str + "\n")
106 
107             # Python 2
108 
109             # unicode_bib_record = unicode(attached_holdings_str)
110 
111             # Python 3
112 
113             unicode_bib_record = str(bib_record_str)
114             if re.search("<errorsExist>true</errorsExist>", unicode_bib_record):
115                 self.error_file.write("MMS ID " + mms_id + " not in system\n")
116                 self.errorCount += 1
117                 print("MMS ID " + mms_id + " not in system\n")
118                 continue
119 
120             holdings_count_match = re.search(
121                 r'holdings\stotal_record_count\="(\d+)"', attached_holdings_str
122             )
123             holdingsCount = int(holdings_count_match.group(1))
124 
125             if holdingsCount == 0:
126                 self.error_file.write("No holdings for MMS ID" + mms_id + "\n")
127                 print("No holdings for MMS ID" + mms_id + "\n")
128                 errorCount += 1
129                 continue
130 
131             # Python 2
132             # unicode_attached_holdings = unicode(attached_holding_str)
133 
134             # Python 3
135 
136             unicode_attached_holdings = str(attached_holdings_str)
137 
138             # print(unicode_attached_holdings)
139             # sys.exit()
140 
141             bib_record = pym.parse_xml_to_array(io.StringIO(unicode_bib_record))
142 
143             tree_orig = et.ElementTree(et.fromstring(attached_holdings_str))
144 
145             root_orig = tree_orig.getroot()
146 
147             # for element in root_orig.iter():
148             #    print(element.text)
149             #    sys.exit()
150             holdings_xml_string = (
151                 '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><holdings>'
152             )
153             for attached_holding in root_orig.findall(".//holding"):
154                 print("\n\nHolding: " + str(et.tostring(attached_holding)) + "\n")
155 
156                 holding_id = attached_holding.find("holding_id").text
157 
158                 print("\nHolding ID: " + str(holding_id) + "\n")
159 
160                 try:
161                     holding_record = requests.get(
162                         self.bib_url
163                         + str(mms_id)
164                         + "/holdings/"
165                         + str(holding_id)
166                         + "?apikey="
167                         + self.sandbox_bib_api_key
168                     )
169 
170                 except:
171                     print(
172                         "Can't retrieve holding with MMS ID: "
173                         + mms_id
174                         + " and holding ID: "
175                         + str(holding_id)
176                         + "\n"
177                     )
178                     self.error_file.write(
179                         "Can't retrieve holding with MMS ID: "
180                         + mms_id
181                         + " and holding ID: "
182                         + str(holding_id)
183                         + "\n"
184                     )
185                     self.errorCount += 1
186                     continue
187                 holding_string = holding_record.content.decode("utf-8")
188 
189                 holding_string = holding_string.replace(
190                     '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>', ""
191                 )
192 
193                 holdings_xml_string += holding_string
194 
195             holdings_xml_string += "</holdings>"
196 
197             # Python 2
198             # unicode_holdings_xml_string = unicode(holdings_xml_string, 'utf-8')
199 
200             # Python 3
201             unicode_holdings_xml_string = holdings_xml_string
202 
203             b = 1
204 
205             tree = et.ElementTree(et.fromstring(unicode_holdings_xml_string))
206             root = tree.getroot()
207 
208             countList = []
209             for five_forty_one in bib_record[0].get_fields("541"):
210                 found541 = False
211                 fiveFortyOneCount += 1
212                 subfield_3 = five_forty_one["3"]
213                 # if not subfield_3 in all541:
214                 #     all541.append(subfield_3)
215                 print("\n\nRepeated 541 subfield 3: \n" + str(subfield_3) + "\n\n")
216                 print("\n\n541: \n" + str(five_forty_one) + "\n\n")
217 
218                 try:
219                     location_541_match = re.search(
220                         r"^(.+Library|TISCH|HHSL|MUSIC|GINN|VET|Tisch|Ginn|Music|Vet|Hirsh|EUR)[ ]?(.+)?([ ]print)?[ ]+copy",
221                         subfield_3,
222                         re.IGNORECASE,
223                     )
224                     library_541 = location_541_match.group(1)
225                     library_541 = library_541.encode("utf-8", "replace").decode()
226                 except:
227                     print(
228                         "Library or location in 541 for MMS ID: "
229                         + str(mms_id)
230                         + " and holding ID: "
231                         + str(holding_id)
232                         + " is not retrievable or is not an expected value\n"
233                     )
234                     self.error_file.write(
235                         "Library or location in 541 for MMS ID: "
236                         + str(mms_id)
237                         + " is not retrievable or is not an expected value\n"
238                     )
239                     errorCount += 1
240                     continue
241 
242                 print(
243                     "\nLibrary: <boundary>"
244                     + library_541
245                     + "</boundary>"
246                     + "Data type: "
247                     + str(type(library_541))
248                     + "\n"
249                 )
250 
251                 location_541 = ""
252                 library = ""
253                 location = ""
254                 location_code = ""
255                 location_description = ""
256                 location_suffix = ""
257                 try:
258                     location_541 = location_541_match.group(2)
259                     location_541 = location_541.encode("utf-8", "replace")
260                 except:
261                     location_541 = ""
262 
263                 try:
264                     location_541 = location_541.decode("utf-8")
265                 except:
266                     pass
267 
268                 if (
269                     library_541 == "Tisch Library"
270                     or str(library_541) == "TISCH"
271                     or str(library_541) == "Tisch"
272                 ):
273                     library = "TISCH"
274                 elif (
275                     str(library_541) == "Ginn Library"
276                     or str(library_541) == "GINN"
277                     or str(library_541) == "Ginn"
278                 ):
279                     library = "GINN"
280                 elif (
281                     library_541 == "Lilly Music Library"
282                     or str(library_541) == "MUSIC"
283                     or str(library_541) == "Music"
284                 ):
285                     library = "MUSIC"
286                 elif (
287                     library_541 == "W. Van Alan Clark, Jr. Library"
288                     or str(library_541) == "SMFA"
289                 ):
290                     library = "SMFA"
291                 elif (
292                     library_541 == "Webster Family Library"
293                     or str(library_541) == "VET"
294                     or str(library_541) == "Vet"
295                 ):
296                     library = "VET"
297                 elif (
298                     library_541 == "Hirsch Health Sciences Library"
299                     or str(library_541) == "Hirsh Health Sciences Library"
300                     or str(library_541) == "HHSL"
301                     or str(library_541) == "Hirsh"
302                 ):
303                     library = "HIRSH"
304                 elif library_541 == "EUR":
305                     library = "Talloires"
306                 else:
307                     print(
308                         "Library in 541 for MMS ID: "
309                         + str(mms_id)
310                         + " is not retrievable or is not an expected value\n"
311                     )
312                     self.error_file.write(
313                         "Library in 541 for MMS ID: "
314                         + str(mms_id)
315                         + " is not retrievable or is not an expected value\n"
316                     )
317                     errorCount += 1
318                     continue
319 
320                 print("\nLibrary for 852 from 541: " + library + "\n")
321                 print("Location_541:               " + str(location_541) + "\n")
322 
323                 for full_holding in root.findall("holding"):
324                     print(
325                         "\nHolding record " + str(b) + ": \n" + str(full_holding) + "\n"
326                     )
327                     b += 1
328                     holding_id = full_holding.find("holding_id").text
329                     c = 0
330                     print("541: \n" + str(bib_record))
331 
332                     holding = pym.parse_xml_to_array(
333                         io.StringIO(et.tostring(full_holding).decode("utf-8"))
334                     )[0]
335 
336                     full_holding_string = et.tostring(full_holding)
337 
338                     foundLocation = False
339 
340                     library_locations = mappings[library]
341 
342                     for dict_location in library_locations:
343                         if location_541.lower() in dict_location.lower():
344                             location_description = dict_location
345                             foundLocation = True
346                             break
347 
348                     if str(location_541) != "" and foundLocation == True:
349                         location_code = mappings[library][location_description]
350 
351                     elif (
352                         str(location_541) == ""
353                         and holding["852"]["b"] == library
354                         and library not in countList
355                     ):
356                         location_code = holding["852"]["c"]
357                         countList.append(library)
358                         foundLocation == True
359                     # elif holdingsCount > 1:
360                     #     print("No location specified in 541, but more than one holding in record for " + str(mms_id) + "\n")
361                     #     error_file.write("No location specified in 541, but more than one holding in record for " + str(mms_id) + "\n")
362                     #     errorCount += 1
363                     #     continue
364 
365                     # library_and_location = library + location_suffix
366 
367                     # print("Library and location: " + library_and_location + "\n\n")
368 
369                     if foundLocation == True:
370                         print("Location code: " + location_code + "\n")
371                         if holding["852"]["c"] == location_code:
372                             found541 = True
373                             success = self.update_holding(
374                                 holding,
375                                 holding_id,
376                                 full_holding_string,
377                                 five_forty_one,
378                                 mms_id,
379                             )
380                             # matched541.append(subfield_3)
381                             if success == True:
382                                 successCount += 1
383                             else:
384                                 print(
385                                     "Couldn't write holding "
386                                     + str(holding_id)
387                                     + " for "
388                                     + str(mms_id)
389                                     + "to Alma via the API.\n"
390                                 )
391                                 self.error_file.write(
392                                     "Couldn't write holding "
393                                     + str(holding_id)
394                                     + " for "
395                                     + str(mms_id)
396                                     + "to Alma via the API.\n"
397                                 )
398                                 errorCount += 1
399                                 continue
400 
401                     else:
402                         # print("Could not match location field from 541 to a location in Alma for " + str(mms_id) + ". This might be because there is no location in the 541, there's no matching library, or there's a typo in the 541 location.\n")
403                         # error_file.write("Could not match location field from 541 to a location in Alma for " + str(mms_id) + ". This might be because there is no location in the 541, there's no matching library, or there's a typo in the 541 location.\n")
404                         # mismatchCount += 1
405                         continue
406 
407                 if found541 == False:
408                     print(
409                         "The 541 for bib record "
410                         + str(mms_id)
411                         + " could not match to a holding location.\n"
412                     )
413                     self.error_file.write(
414                         "The 541 for bib record "
415                         + str(mms_id)
416                         + " could not match to a holding location.\n"
417                     )
418                     errorCount += 1
419 
420                 # Python 2
421 
422                 # holding = pym.parse_xml_to_array(io.StringIO(unicode(et.tostring(full_holding))))[0]
423 
424                 # Python 3
425 
426         print(
427             "Number of 541s:                                                       "
428             + str(fiveFortyOneCount)
429             + "\n"
430         )
431         self.count_file.write(
432             "Number of 541s:                                            "
433             + str(fiveFortyOneCount)
434             + "\n"
435         )
436         print(
437             "Records successfully updated:                                         "
438             + str(successCount)
439             + "\n"
440         )
441         self.count_file.write(
442             "Records successfully updated:                              "
443             + str(successCount)
444             + "\n"
445         )
446         print(
447             "Records that couldn't be updated.  Check error file:                  "
448             + str(errorCount)
449             + "\n"
450         )
451         self.count_file.write(
452             "Records that couldn't be updated.  Check error file:       "
453             + str(errorCount)
454             + "\n"
455         )
456         # print("Matching errors between 541 and holdings. Check error file:           " + str(mismatchCount) + "\n")
457         # count_file.write("atching errors between 541 and holdings. Check error file: " + str(mismatchCount) + "\n")
458 
459         self.count_file.seek(0)
460         self.output_file.seek(0)
461         self.error_file.seek(0)
462 
463         # Step 2: Create ZIP Archive in Memory
464         zip_buffer = io.BytesIO()
465         with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
466             zip_file.writestr("Count File.txt", self.count_file.getvalue())
467             zip_file.writestr("Errors.txt", self.error_file.getvalue())
468             zip_file.writestr("Output File.xml", self.output_file.getvalue())
469 
470         zip_buffer.seek(0)
471 
472         # Step 3: Return ZIP File for Download
473         return send_file(
474             zip_buffer,
475             mimetype="application/zip",
476             as_attachment=True,
477             download_name="rollup_files.zip",
478         )
479 
480     def update_holding(
481         holding, holding_id, full_holding_string, five_forty_one, mms_id, self
482     ):
483         holding.add_field(five_forty_one)
484         print("Holding with new field: \n" + str(holding) + "\n\n\n")
485         updated_holding = pym.record_to_xml(holding).decode("utf-8")
486 
487         full_holding_string = full_holding_string.decode("utf-8")
488 
489         full_updated_holding = re.sub(
490             r"<record>(.+)</record>", updated_holding, full_holding_string
491         )
492 
493         print("Updated XML Holding Record: \n" + full_updated_holding + "\n")
494 
495         full_updated_holding = full_updated_holding.replace(
496             '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>', ""
497         )
498 
499         # success = True
500 
501         # faulty_xml = "<holding></holding>"
502         #
503         # # full_holdings_xml = root.find('holding/holding_id=')
504         #
505         #
506         response = requests.put(
507             self.bib_url
508             + str(mms_id)
509             + "/holdings/"
510             + str(holding_id)
511             + "?apikey="
512             + secrets_local.bib_api_key,
513             data=full_updated_holding,
514             headers=headers,
515         )
516         #
517         time.sleep(2)
518         print(response.content)
519         # #
520         # #
521         # # # response = requests.put("https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/" + str(mms_id) + "/holdings/" + str(holding_id) + "?apikey=", data=full_updated_holding, headers=headers)
522         # # #
523         # # # print(response.content)
524         if re.search("<errorsExist>true</errorsExist>", response.content):
525             print("Couldn't write back to Alma for MMS ID: " + mms_id + "\n")
526             self.error_file.write(
527                 "Couldn't write back to Alma for MMS ID: " + mms_id + "\n"
528             )
529             success = False
530         else:
531             self.output_file.write(
532                 "<MMS_ID_"
533                 + mms_id
534                 + ">"
535                 + full_updated_holding
536                 + "</MMS_ID_"
537                 + mms_id
538                 + ">"
539             )
540 
541             success = True
542 
543         # print(response.content)
544         #
545         # print(success)
546         #
547         # sys.exit()
548         return success
549 
550     def getLocations():
551         url = (
552             "https://api-na.hosted.exlibrisgroup.com/almaws/v1/analytics/reports?apikey="
553             + secrets_local.analytics_api_key
554         )
555         limit = "&limit=1000"
556         format = "&format=xml"
557         path = "&path=%2Fshared%2FTufts+University%2FReports%2FCataloging%2FAdding+541+to+Holdings+Records%2FLocation+Name-Location+Code"
558 
559         report = requests.get(url + format + path + limit)
560 
561         # print("\nReport Content: \n" + report.content)
562 
563         report_outfile = open("Output/list of codes and locations.xml", "w+")
564 
565         # report_str = report.content.decode('utf-8')
566         report_outfile.write(str(report.content))
567 
568         # print("\n\nReport: \n" + report.content)
569 
570         report_outfile.close()
571 
572         tree = et.ElementTree(et.fromstring(report.content))
573 
574         # print("\nTree: " + tree.text + "\n")
575 
576         root = tree.getroot()
577 
578         print("\nRoot: \n" + str(root.text) + "\n")
579 
580         reportDict = {}
581         # for element in root.iter('{urn:schemas-microsoft-com:xml-analysis:rowset}Row'):
582         # print("\n\nAll Elements: \n" + str(list(root.iter())))
583 
584         for element in root.iter():
585             library = ""
586             code = ""
587             description = ""
588             if re.match(r".*Row", element.tag):
589                 for sub_element in element.iter():
590                     if re.match(r".*Column2", sub_element.tag):
591                         code = sub_element.text
592                     if re.match(r".*Column3", sub_element.tag):
593                         description = sub_element.text
594                     elif re.match(r".*Column1", sub_element.tag):
595                         library = sub_element.text
596 
597             if library in reportDict:
598                 reportDict[library][description] = code
599             else:
600                 reportDict[library] = {}
601                 reportDict[library][description] = code
602 
603         # for c in reportDict:
604         # 	c = c.decode('ascii')
605         # 	for d in reportDict[c]:
606         # 		reportDict[c][d] = reportDict[c][d].decode('ascii')
607         for i in reportDict:
608             for j in reportDict[i]:
609                 print(
610                     "Library: "
611                     + str(i)
612                     + "; Description: "
613                     + str(j)
614                     + "; Code: "
615                     + str(reportDict[i][j])
616                     + "\n"
617                 )
618         return reportDict
619 

File: app/bib_2_holdings_541/routes.py
1 from flask import (
2     Blueprint,
3     request,
4     redirect,
5     url_for,
6     send_file,
7     current_app,
8     render_template,
9 )
10 from werkzeug.utils import secure_filename
11 import os
12 from app.bib_2_holdings_541.bib_2_holdings_541 import Bib2Holdings541
13 
14 
15 blueprint_541 = Blueprint("bib_2_holdings_541", __name__)
16 
17 
18 @blueprint_541.route("/upload", methods=["POST"])
19 def upload_file():
20     if request.method == "POST":
21         # Retrieve the file from the form field named 'file'
22         file = request.files.get("file")
23         if not file:
24             return "No file provided", 400
25 
26         # Optional: Check for additional form fields, e.g., a checkbox for ISBN processing
27         isbn_bool = request.form.get("isbn_bool", "false").lower() == "true"
28 
29         bib2Holdings541 = Bib2Holdings541()
30         return bib2Holdings541.process()
31     else:
32         # Render a simple upload form (ensure you have an 'upload.html' template)
33         return render_template("upload.html")
34 
35 
36 @blueprint_541.route("/", methods=["GET"])
37 def index():
38     return render_template("bib_2_holdings_541.html")
39 

File: app/main/__init__.py
1 # Import the main blueprint from routes.py
2 from .routes import main_blueprint
3 

File: app/main/routes.py
1 from flask import Blueprint, render_template
2 
3 # Define the main blueprint
4 main_blueprint = Blueprint("main", __name__)
5 
6 
7 # Define the route for the main page
8 @main_blueprint.route("/")
9 def index():
10     """
11     Render the index.html template as the main page.
12     """
13     return render_template("index.html")
14 

File: app/p_and_e_rollup_match/__init__.py
1 from .routes import p_and_e_blueprint
2 

File: app/p_and_e_rollup_match/p_and_e_rollup_match.py
1 import os
2 import pandas as pd
3 import re
4 from flask import (
5     Blueprint,
6     request,
7     redirect,
8     url_for,
9     send_file,
10     current_app,
11     render_template,
12 )
13 from werkzeug.utils import secure_filename
14 import io
15 from io import BytesIO
16 import zipfile
17 
18 
19 def zip_files(filenames):
20     memory_file = BytesIO()
21     with zipfile.ZipFile(memory_file, "w", zipfile.ZIP_DEFLATED) as zf:
22         for filename in filenames:
23             data = open(filename, "rb").read()
24             zf.writestr(os.path.basename(filename), data)
25     memory_file.seek(0)
26     return memory_file
27 
28 
29 class ResourceMatch:
30     def __init__(self, file_path, isbn_bool):
31         self.file_path = file_path
32         self.isbn_bool = isbn_bool
33 
34     def process(self):
35         df = pd.read_excel(
36             self.file_path,
37             engine="openpyxl",
38             sheet_name="Matches with Multiple Resources",
39             dtype=str,
40         )
41         df = df.applymap(lambda x: str(x).replace('"', "") if isinstance(x, str) else x)
42 
43         df = df.applymap(lambda x: str(x).replace('"', "") if isinstance(x, str) else x)
44 
45         print(f"DataFrame shape before grouping: {df.shape}")
46         print(df.head())  # Display first few rows
47 
48         df["ISSN"] = df["ISSN"].apply(lambda x: re.sub(r"\s+", r"; ", x))
49 
50         df = df["ISSN"].str.split(";").explode().reset_index(drop=True)
51 
52         if self.isbn_bool:
53             df["ISBN"] = df["ISBN"].apply(lambda x: re.sub(r"\s+", r"; ", x))
54 
55             df["ISBN(13)"] = df["ISBN(13)"].apply(lambda x: re.sub(r"\s+", r"; ", x))
56 
57         rollup_columns = []
58 
59         if self.isbn_bool:
60             rollup_columns = [
61                 "Collection",
62                 "Interface",
63                 "Portfolio ID",
64                 "Coverage",
65                 "Embargo",
66                 "Resource Scope",
67                 "Linked To CZ",
68                 "Open Access",
69                 "Access Type",
70                 "Is Active",
71                 "ISBN",
72                 "ISBN(13)",
73                 "ISBN(Matching Identifier)",
74             ]
75 
76             rollup_columns_sum = [
77                 "Link resolver usage (access)",
78                 "Link resolver usage (appearance)",
79             ]
80 
81         else:
82             rollup_columns = [
83                 "Collection",
84                 "Interface",
85                 "Portfolio ID",
86                 "Coverage",
87                 "Embargo",
88                 "Resource Scope",
89                 "Linked To CZ",
90                 "Open Access",
91                 "Access Type",
92                 "Is Active",
93             ]
94 
95             rollup_columns_sum = [
96                 "Link resolver usage (access)",
97                 "Link resolver usage (appearance)",
98             ]
99         df[rollup_columns_sum] = df[rollup_columns_sum].fillna(0)
100         df[rollup_columns_sum] = df[rollup_columns_sum].astype(int)
101 
102         groupby_columns = []
103         for column in df.columns:
104             if column not in rollup_columns and column not in rollup_columns_sum:
105                 groupby_columns.append(column)
106 
107         print(groupby_columns)
108 
109         print(rollup_columns)
110 
111         print(rollup_columns_sum)
112         df.fillna("", inplace=True)
113         print(f"Actual DataFrame columns: {df.columns.tolist()}")
114 
115         # Create aggregation dictionary dynamically
116         agg_dict = {
117             col: lambda x: "; ".join(set(x.astype(str))) for col in rollup_columns
118         }
119 
120         sum_dict = {col: lambda x: x.astype(int).sum() for col in rollup_columns_sum}
121         print(agg_dict)
122 
123         print(sum_dict)
124 
125         # Merge both aggregation strategies
126         agg_dict.update(sum_dict)
127         # Apply groupby and aggregation
128         df_grouped = df.groupby(groupby_columns, as_index=False).agg(agg_dict)
129         df_grouped = df_grouped[df.columns]
130         print(df_grouped)
131 
132         df2 = pd.read_excel(
133             self.file_path,
134             engine="openpyxl",
135             sheet_name="Matches with Single Resource",
136             dtype=str,
137         )
138         df[rollup_columns_sum] = df[rollup_columns_sum].fillna(0)
139         df[rollup_columns_sum] = df[rollup_columns_sum].astype(int)
140 
141         isbn_columns = ["ISBN", "ISBN(13)", "ISBN(Matching Identifier)"]
142 
143         single_match_groupby_columns = (
144             groupby_columns + rollup_columns + rollup_columns_sum
145         )
146 
147         if self.isbn_bool:
148             isbn_dict = {
149                 col: lambda x: "; ".join(set(x.astype(str))) for col in isbn_columns
150             }
151             df2_grouped = df2.groupby(single_match_groupby_columns, as_index=False).agg(
152                 isbn_dict
153             )
154             df2_grouped = df2_grouped[df2.columns]
155 
156             df2 = df2_grouped
157 
158         # Remove double quotes from all values in the DataFrame
159         df2 = df2.applymap(lambda x: x.replace('"', "") if isinstance(x, str) else x)
160 
161         # Append df2 to df
162         df_combined = pd.concat([df_grouped, df2], ignore_index=True)
163 
164         no_match_df = pd.read_excel(
165             self.file_path,
166             engine="openpyxl",
167             sheet_name="No Matches or No Resources",
168             dtype=str,
169         )
170         no_match_df = no_match_df.applymap(
171             lambda x: str(x).replace('"', "") if isinstance(x, str) else x
172         )
173 
174         try:
175             no_match_df = no_match_df.rename(columns={"MMS Id": "MMS ID"})
176 
177         except:
178             no_match_df = no_match_df
179 
180         print(no_match_df)
181 
182         no_match_df = no_match_df.fillna("")
183         if self.isbn_bool:
184             no_match_group_by_columns = []
185             for column in no_match_df.columns:
186                 if column != "ISBN(Matching Identifier)":
187                     no_match_group_by_columns.append(column)
188             print(no_match_group_by_columns)
189             isbn_dict_2 = {
190                 col: lambda x: "; ".join(set(x.astype(str)))
191                 for col in ["ISBN(Matching Identifier)"]
192             }
193 
194             no_match_df["ISBN(Matching Identifier)"] = no_match_df[
195                 "ISBN(Matching Identifier)"
196             ].fillna("")
197             no_match_df["ISBN(Matching Identifier)"] = no_match_df[
198                 "ISBN(Matching Identifier)"
199             ].astype(str)
200 
201             print(isbn_dict_2)
202 
203             # Debug print: Check columns
204             print("Available columns in no_match_df:", no_match_df.columns.tolist())
205             print("Grouping by columns:", no_match_group_by_columns)
206 
207             # Ensure grouping columns exist
208             no_match_group_by_columns = [
209                 col for col in no_match_group_by_columns if col in no_match_df.columns
210             ]
211             print("Updated grouping columns:", no_match_group_by_columns)
212 
213             # Ensure ISBN(Matching Identifier) is not empty
214             no_match_df = no_match_df[
215                 no_match_df["ISBN(Matching Identifier)"].notna()
216                 & (no_match_df["ISBN(Matching Identifier)"] != "")
217             ]
218             if no_match_df.empty:
219                 print(
220                     "⚠️ Warning: no_match_df is empty after removing empty ISBN(Matching Identifier). Skipping grouping."
221                 )
222             else:
223                 no_match_df["ISBN(Matching Identifier)"] = no_match_df[
224                     "ISBN(Matching Identifier)"
225                 ].astype(str)
226                 no_match_df_grouped = no_match_df.groupby(
227                     no_match_group_by_columns, as_index=False
228                 ).agg(isbn_dict_2)
229 
230                 print("After grouping:", no_match_df_grouped)
231 
232                 no_match_df = no_match_df_grouped
233             # no_match_df_grouped = no_match_df.groupby(no_match_group_by_columns, as_index=False).agg(isbn_dict_2)
234             #
235             # print("just after grouping")
236             #
237             # print(no_match_df_grouped)
238             # no_match_df_grouped = no_match_df_grouped[no_match_df.columns]
239             #
240             # print("after matching columns")
241             # print(no_match_df_grouped)
242             #
243             #
244             # no_match_df_grouped = no_match_df_grouped[no_match_df.columns]
245             #
246             # print(no_match_df_grouped)
247             # no_match_df = no_match_df_grouped
248             #
249             # print(no_match_df)
250         df_combined = pd.concat([df_grouped, df2], ignore_index=True)
251         # Write the combined dataframe to an in-memory Excel file
252         output_combined = io.BytesIO()
253         df_combined.to_excel(output_combined, index=False)
254         output_combined.seek(0)
255 
256         output_no_match = io.BytesIO()
257 
258         no_match_df.to_excel(output_no_match, index=False)
259 
260         output_no_match.seek(0)
261 
262         # Step 2: Create ZIP Archive in Memory
263         zip_buffer = io.BytesIO()
264         with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
265             zip_file.writestr(
266                 "Merged Single and Multiple Resources with Rolled up Multiple Resources.xlsx",
267                 output_combined.getvalue(),
268             )
269             zip_file.writestr("No Match.xlsx", output_no_match.getvalue())
270 
271         zip_buffer.seek(0)
272 
273         # Step 3: Return ZIP File for Download
274         return send_file(
275             zip_buffer,
276             mimetype="application/zip",
277             as_attachment=True,
278             download_name="rollup_files.zip",
279         )
280 

File: app/p_and_e_rollup_match/routes.py
1 from flask import (
2     Blueprint,
3     request,
4     redirect,
5     url_for,
6     send_file,
7     current_app,
8     render_template,
9 )
10 from werkzeug.utils import secure_filename
11 import os
12 from .p_and_e_rollup_match import ResourceMatch
13 
14 p_and_e_blueprint = Blueprint("p_and_e", __name__)
15 
16 
17 @p_and_e_blueprint.route("/upload", methods=["POST"])
18 def upload_file():
19     if request.method == "POST":
20         # Retrieve the file from the form field named 'file'
21         file = request.files.get("file")
22         if not file:
23             return "No file provided", 400
24 
25         # Optional: Check for additional form fields, e.g., a checkbox for ISBN processing
26         isbn_bool = request.form.get("isbn_bool", "false").lower() == "true"
27 
28         resource_match = ResourceMatch(file, isbn_bool)
29         return resource_match.process()
30     else:
31         # Render a simple upload form (ensure you have an 'upload.html' template)
32         return render_template("upload.html")
33 
34 
35 @p_and_e_blueprint.route("/", methods=["GET"])
36 def index():
37     return render_template("bib_2_holdings_541.html")
38 

File: app/routes.py
1 from flask import request, render_template, Blueprint, g
2 import redis
3 import json
4 import os
5 import app.p_and_e_rollup_match.p_and_e_rollup_match
6 import app.barnes_and_noble.barnes_and_noble
7 import app.bib_2_holdings_541.bib_2_holdings_541
8 
9 
10 main = Blueprint("main", __name__)
11 
12 
13 @main.route("/resource_match", methods=["GET", "POST"])
14 def resource_match():
15     return render_template("resource_match.html")
16 

File: app/static/styles.css
1 @property --tufts-blue {
2     syntax: "<color>";
3     inherits: false;
4     initial-value: #3172AE;
5   }
6   @property --heading-blue {
7     syntax: "<color>";
8     inherits: false;
9     initial-value: #002E6D;
10   }
11   @property --light-gray{
12     syntax: "<color>";
13     inherits: false;
14     initial-value: #F2F2F2;
15   }
16 
17 body {
18     font-family: Arial, sans-serif;
19     margin: 0;
20 }
21 header{
22   background-color: var(--tufts-blue);
23   width: 100%;
24   
25 }
26 
27 form{
28   display: flex;
29   flex-flow: row wrap;
30   align-items: center;
31 }
32 header .logo{
33   padding: 1em;
34   font-size: 1.5em;
35   font-weight: bold;
36   color: white;
37 }
38 
39 header .logo a{
40   padding: .3em;
41   font-size: .75em;
42   font-weight: bold;
43   color: white;
44 }
45 
46 header .logo .subtext{
47   font-size: 1em;
48   font-weight: initial;
49   color: white;
50 }
51 
52 .content{
53     margin: 0 2em;
54 }
55 h1, h2{
56   color: var(--heading-blue);
57 }
58 h1{
59   margin-top: 1em;
60 }
61 h2{
62  margin-top: 2em;
63 }
64 .vhide{
65     position: absolute !important;
66     overflow: hidden !important;
67     clip: rect(1px, 1px, 1px, 1px);
68     width: 1px;
69     height: 1px;
70     word-wrap: normal;
71 }
72 
73 #hourglass {
74   position: fixed;
75   top: 50%;
76   left: 50%;
77   transform: translate(-50%, -50%);
78   z-index: 9999;
79 }
80 
81 label{
82 	width:5%;
83 }
84 table{
85  @media all and (max-width: 500px){
86     width: 100%;
87  }
88  width: 60%;
89  
90 }
91 
92 
93 table td{
94     padding: 0.5em;
95 
96 }
97 table th{
98     border-bottom: 1px solid gray;
99 }
100 table tr:nth-of-type(even){
101     background-color: var(--light-gray);
102 }
103 
104 #footer{height: 110px; background: repeat-x top left #427dc1;}
105 #footer a {color:white}
106 #float-first {    float: left; clear: none;}
107 				#float-second {    float: left;clear: none;}
108 button{
109     background-color: darkblue;
110     color: white;
111     padding: 0.5em;
112     border: none;
113     border-radius: 0.25em;
114 }
115 input[type="file"]{
116     padding: 0.5em;
117     background-color: var(--light-gray);
118 }
119 #hourglass {
120     position: fixed;
121     top: 50%;
122     left: 50%;
123     transform: translate(-50%, -50%);
124     z-index: 9999;
125 }
126 
127 .input{
128 	float:left;
129 	width:15%;
130 	clear:both;
131 }
132 .spinner {
133     border: 16px solid #f3f3f3;
134     border-top: 16px solid #3498db;
135     border-radius: 50%;
136     width: 120px;
137     height: 120px;
138     animation: spin 2s linear infinite;
139 }
140 @keyframes spin {
141     0% { transform: rotate(0deg); }
142     100% { transform: rotate(360deg); }
143 }
144 

File: app/templates/barnes_and_noble.html
1 {% extends "base.html" %}
2 {% block content %}
3     <h1>Upload an Excel file for Barnes and Noble Overlap Analysis</h1>
4     <form action="/barnes_and_noble/upload" method="post" enctype="multipart/form-data" onsubmit="submitFormWithFetch(event, this)">
5         <input type="file" name="file" required>
6         <button type="submit">Upload</button>
7     </form>
8 {% endblock %}
9 

File: app/templates/base.html
1 <!DOCTYPE html>
2 <html lang="en">
3 <head>
4     <meta charset="UTF-8">
5     <meta name="viewport" content="width=device-width, initial-scale=1.0">
6     <title>Self Service Portal</title>
7     <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
8 
9     <link rel="stylesheet" href="{{ url_for('static', filename='styles.css') }}"> 
10     <script src="https://cdnjs.cloudflare.com/ajax/libs/xlsx/0.17.0/xlsx.full.min.js"></script>
11 
12     <script>
13         async function submitFormWithFetch(event, form) {
14             event.preventDefault();  // Prevent normal form submission
15             showHourglass();
16 
17             let formData = new FormData(form);
18 
19             try {
20                 let response = await fetch(form.action, {
21                     method: "POST",
22                     body: formData
23                 });
24 
25                 if (!response.ok) throw new Error("Network response was not ok");
26 
27                 let blob = await response.blob();
28                 let filename = getFilenameFromResponse(response) || "download.xlsx";
29 
30                 let link = document.createElement("a");
31                 link.href = window.URL.createObjectURL(blob);
32                 link.download = filename;
33                 document.body.appendChild(link);
34                 link.click();
35                 document.body.removeChild(link);
36                 
37             } catch (error) {
38                 alert("Error downloading file: " + error.message);
39             } finally {
40                 hideHourglass();
41             }
42         }
43 
44         function showHourglass() {
45             $("#hourglass").show();
46         }
47 
48         function hideHourglass() {
49             $("#hourglass").hide();
50         }
51 
52         function getFilenameFromResponse(response) {
53             let disposition = response.headers.get("Content-Disposition");
54             if (disposition && disposition.includes("filename=")) {
55                 return disposition.split("filename=")[1].replace(/['"]/g, "");
56             }
57             return null;
58         }
59     </script>
60 </head>
61 <body>
62     <div id="hourglass" style="display: none;">
63         <div class="spinner"></div>
64     </div>
65     <header>
66         <div class="logo">Tufts Libraries&nbsp;&nbsp;<span class="subtext">Self Service Portal</span><p><a href="/">Home</a></p></div></div> 
67         
68     </header>
69     <div class="content">
70         {% block content %}{% endblock %}
71     </div>
72     <!-- <div id="footer">
73         <div>
74         <div id="float-first">
75         <img src="tufts-logo-univ-white.svg" class="footer" />
76         <br />
77         <span style="font-size: .9em">Copyright &copy;2013 <a href="http://www.tufts.edu">Tufts University</a> <br /><span style="color:white;">All Rights Reserved.</span></span>
78         </div>
79         
80         <div id="float-second">
81         <table id="footer_table" style="font-size: .9em" cellspacing="0">
82         
83                         <tr>
84                             <td>Ginn Library</td>
85         
86                             <td>
87                                 <a href="mailto:ginncirc@tufts.edu">ginncirc@tufts.edu</a>
88                             </td>
89         
90                             <td>617-627-3852</td>
91         
92                         </tr>
93                         <tr>
94                             <td>Hirsh Health Sciences Library</td>
95         
96                             <td>
97                                 <a href="mailto:hhsl@tufts.edu">hhsl@tufts.edu</a>
98                             </td>
99                             <td>617-636-6706</td>
100         
101                         </tr>
102                         <tr>
103                             <td>Lilly Music Library</td>
104         
105                             <td>
106                                 <a href="mailto:musiclib@tufts.edu">musiclib@tufts.edu</a>
107                             </td>
108                             <td>617-627-3594</td>
109         
110                         </tr>
111                         <tr>
112                             <td>SMFA Library</td>
113         
114                             <td>
115                                 <a href="mailto:smfalibrary@tufts.edu ">smfalibrary@tufts.edu</a>
116                             </td>
117                             <td>617-627-0080</td>
118         
119                         </tr>
120                         <tr>
121                             <td>Tisch Library</td>
122         
123                             <td>
124                                 <a href="mailto:tischfrontline@elist.tufts.edu"
125                                     >tischfrontline@elist.tufts.edu</a>
126                             </td>
127                             <td>617-627-3347</td>
128         
129                         </tr>
130                         <tr>
131                             <td>Webster Vet Library</td>
132         
133                             <td>
134                                 <a href="mailto:webvet@tufts.edu">webvet@tufts.edu</a>
135                             </td>
136                             <td>508-839-7957</td>
137         
138                         </tr>
139         
140                     </table>
141         
142         <br />
143         
144         </div>
145         </div></div> -->
146         
147 
148 </body>
149 </html>
150 

File: app/templates/bib_2_holdings_541.html
1 {% extends "base.html" %}
2 {% block content %}
3     <h1 style="color:red">ALMA SANDBOX</h1>
4     <h1>Bib 2 Holdings 541</h1>
5     <p>Upload a single column text file with each MMS on a separate line, of records for which you want to apply the bib 541 to the holding record.</p>
6     <form action="/bib_2_holdings_541/upload" method="post" enctype="multipart/form-data" onsubmit="submitFormWithFetch(event, this)">
7         <input type="file" name="file" required>
8         <button type="submit">Upload</button>
9     </form>
10 {% endblock %}
11 

File: app/templates/index.html
1 {% extends "base.html" %}
2 {% block content %}
3     <h1>Self Service Portal</h1>
4 
5     <p>This site contains scripts and processes that libraries use to help with workflows and analysis.  To access these functions, click on one of the links below.</p>
6     <ul><h3>Processes</h3>
7         <li><a href="{{ url_for('barnes_and_noble.index') }}">Barnes and Noble Course Matching</a></li>
8         <li><a href="{{ url_for('p_and_e.index')}}">Physical and Electronic Processing Overlap Analysis</a></li>
9         <li><a href="{{ url_for('bib_2_holdings_541.index')}}">Bib To Holdings 541</a></li>
10 
11 
12     </ul>
13 {% endblock %}
14 

File: app/templates/p_and_e_rollup_match.html
1 {% extends "base.html" %}
2 {% block content %}
3     <h1>Upload a File for P and E Rollup Match</h1>
4     <form action="/p_and_e/upload" method="post" enctype="multipart/form-data" onsubmit="submitFormWithFetch(event, this)">
5         <input type="file" name="file" required>
6         <label for="isbn_bool">Include ISBN Rollup:</label>
7         <input type="checkbox" name="isbn_bool" value="yes">
8         <button type="submit">Upload</button>
9     </form>
10 {% endblock %}
11 

File: app/templates/upload.html
1 <!DOCTYPE html>
2 <html lang="en">
3 <head>
4     <meta charset="UTF-8">
5     <meta name="viewport" content="width=device-width, initial-scale=1.0">
6     <title>File Upload</title>
7 </head>
8 <body>
9     <h1>Upload a File</h1>
10     <form action="/overlap/upload" method="post" enctype="multipart/form-data">
11         <input type="file" name="file" required>
12         <button type="submit">Upload for Overlap Analysis</button>
13     </form>
14     <form action="/resource/upload" method="post" enctype="multipart/form-data">
15         <input type="file" name="file" required>
16         <label for="isbn_bool">Include ISBN Rollup:</label>
17         <input type="checkbox" name="isbn_bool" value="yes">
18         <button type="submit">Upload for Resource Match</button>
19     </form>
20 </body>
21 </html>

File: run.py
1 from flask import Flask, g
2 from app import create_app
3 
4 app = create_app()
5 
6 if __name__ == "__main__":
7     app.run(debug=True)
8 

```

Request: In this app, in which the modules p_and_e_rolloup_match and barnes_and_noble are working, I've just added the module bib_2_holdings_541.   When I try to link to this from the index template containing all, I get sent to p_and_e_rollup_match instead of bib_2_holdings_541.  WHy is this?

================================== Ai Message ==================================

The issue you're experiencing is likely due to a routing conflict or misconfiguration in the Flask application. Let's go through the code to identify and resolve the problem.

### Analysis

1. **Blueprint Registration**: In the `create_app` function in `app/__init__.py`, all blueprints are registered with specific URL prefixes. This is correct and should not cause any conflicts.

2. **Route Definitions**: In `app/p_and_e_rollup_match/routes.py`, the route for the index page is defined as follows:
   ```python
   @p_and_e_blueprint.route("/", methods=["GET"])
   def index():
       return render_template("bib_2_holdings_541.html")
   ```
   This is incorrect because it renders the `bib_2_holdings_541.html` template instead of the intended template for the `p_and_e_rollup_match` module. This is likely causing the confusion when navigating to the `bib_2_holdings_541` route.

3. **Template Links**: In `app/templates/index.html`, the link to the `bib_2_holdings_541` module is defined correctly using the `url_for` function:
   ```html
   <li><a href="{{ url_for('bib_2_holdings_541.index')}}">Bib To Holdings 541</a></li>
   ```

### Solution

To resolve the issue, we need to correct the route definition in `app/p_and_e_rollup_match/routes.py` to render the appropriate template for the `p_and_e_rollup_match` module.

### Code Changes

Let's make the necessary changes to the `app/p_and_e_rollup_match/routes.py` file:

```diff
--- app/p_and_e_rollup_match/routes.py
+++ app/p_and_e_rollup_match/routes.py
@@ -35,5 +35,5 @@
 
 
 @p_and_e_blueprint.route("/", methods=["GET"])
 def index():
-    return render_template("bib_2_holdings_541.html")
+    return render_template("p_and_e_rollup_match.html")
```

### Verification

After making this change, verify the following:

1. Navigate to the index page and click on the "Bib To Holdings 541" link. It should correctly route to the `bib_2_holdings_541` module and render the `bib_2_holdings_541.html` template.

2. Ensure that the "Physical and Electronic Processing Overlap Analysis" link correctly routes to the `p_and_e_rollup_match` module and renders the `p_and_e_rollup_match.html` template.

This concludes a fully working implementation.

2025-04-30T13:48:53.671742
================================ System Message ================================

You will get instructions for code to write.
You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.
Think step by step and reason yourself to the correct decisions to make sure we get it right.
Make changes to existing code and implement new code in the unified git diff syntax. When implementing new code, First lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.

You will output the content of each file necessary to achieve the goal, including ALL code.
Output requested code changes and new code in the unified "git diff" syntax. Example:

```diff
--- example.txt
+++ example.txt
@@ -6,3 +6,4 @@
     line content A
     line content B
+    new line added
-    original line X
+    modified line X with changes
@@ -26,4 +27,5 @@
         condition check:
-            action for condition A
+            if certain condition is met:
+                alternative action for condition A
         another condition check:
-            action for condition B
+            modified action for condition B
```

Example of a git diff creating a new file:

```diff
--- /dev/null
+++ new_file.txt
@@ -0,0 +1,3 @@
+First example line
+
+Last example line
```

RULES:
-A program will apply the diffs you generate exactly to the code, so diffs must be precise and unambiguous!
-Every diff must be fenced with triple backtick ```.
-The file names at the beginning of a diff, (lines starting with --- and +++) is the relative path to the file before and after the diff.
-LINES TO BE REMOVED (starting with single -) AND LINES TO BE RETAIN (no starting symbol) HAVE TO REPLICATE THE DIFFED HUNK OF THE CODE EXACTLY LINE BY LINE. KEEP THE NUMBER OF RETAIN LINES SMALL IF POSSIBLE.
-EACH LINE IN THE SOURCE FILES STARTS WITH A LINE NUMBER, WHICH IS NOT PART OF THE SOURCE CODE. NEVER TRANSFER THESE LINE NUMBERS TO THE DIFF HUNKS.
-AVOID STARTING A HUNK WITH AN EMPTY LINE.
-ENSURE ALL CHANGES ARE PROVIDED IN A SINGLE DIFF CHUNK PER FILE TO PREVENT MULTIPLE DIFFS ON THE SAME FILE.


As far as compatible with the user request, start with the "entrypoint" file, then go to the ones that are imported by that file, and so on.
Please note that the code should be fully functional. No placeholders.

Follow a language and framework appropriate best practice file naming convention.
Make sure that files contain all imports, types etc.  The code should be fully functional. Make sure that code in different files are compatible with each other.
Ensure to implement all code, if you are unsure, write a plausible implementation.
Include module dependency or package manager dependency definition file.
Before you finish, double check that all parts of the architecture is present in the files.

When you are done, write finish with "this concludes a fully working implementation".

Useful to know:
Almost always put different classes in different files.
Always use the programming language the user asks for.
For Python, you always create an appropriate requirements.txt file.
For NodeJS, you always create an appropriate package.json file.
Always add a comment briefly describing the purpose of the function definition.
Add comments explaining very complex bits of logic.
Always follow the best practices for the requested languages for folder/file structure and how to package the project.


Python toolbelt preferences:
- pytest
- dataclasses


================================ Human Message =================================

```
File: app/__init__.py
1 from flask import Flask
2 from app.main import main_blueprint
3 from app.barnes_and_noble import barnes_and_noble_blueprint
4 from app.p_and_e_rollup_match import p_and_e_blueprint
5 from app.bib_2_holdings_541 import blueprint_541
6 from dotenv import load_dotenv
7 
8 
9 def create_app():
10     app = Flask(__name__)
11 
12     app.register_blueprint(main_blueprint)
13     app.register_blueprint(barnes_and_noble_blueprint, url_prefix="/barnes_and_noble")
14     app.register_blueprint(p_and_e_blueprint, url_prefix="/p_and_e")
15     app.register_blueprint(blueprint_541, url_prefix="/bib_2_holdings_541")
16 
17     load_dotenv()
18     return app
19 

File: app/app.py
1 from flask import Flask, Blueprint, render_template
2 import pandas as pd
3 import os
4 
5 # from main.routes import main_blueprint
6 # from barnes_and_noble.routes import barnes_and_noble_blueprint
7 # from p_and_e_rollup_match.routes import p_and_e_blueprint
8 
9 app = Flask(__name__)
10 
11 
12 # app.register_blueprint(main_blueprint)
13 # app.register_blueprint(barnes_and_noble_blueprint, url_prefix="/barnes_and_noble")
14 # app.register_blueprint(p_and_e_blueprint, url_prefix="/p_and_e")
15 if __name__ == "__main__":
16     app.run(debug=True)
17 

File: app/barnes_and_noble/__init__.py
1 from .routes import barnes_and_noble_blueprint
2 

File: app/barnes_and_noble/barnes_and_noble.py
1 import os
2 import pandas as pd
3 import requests
4 import json
5 import re
6 from flask import current_app
7 from werkzeug.utils import secure_filename
8 
9 
10 class OverlapAnalysis:
11     def __init__(self, file_path):
12         self.file_path = file_path
13 
14     def process(self):
15         # Load the Excel file
16         df_input = pd.read_excel(self.file_path, dtype=str, engine="openpyxl")
17         df_input["course_code"] = ""
18         df_input["section"] = ""
19         df_input["course_name"] = ""
20         df_input["processing_department"] = ""
21         df = df_input.copy()
22 
23         for column in df.columns:
24             df[column] = df[column].astype(str)
25             df[column] = df[column].apply(lambda x: x.replace('"', ""))
26 
27         # Process each row
28         for index, row in df.iterrows():
29             semester = row["Term"]
30             if "F" in semester:
31                 semester = semester.replace("F", "Fa")
32             elif "W" in semester:
33                 semester = semester.replace("W", "Sp")
34 
35             course = row["Course"]
36             section = row["Sec"]
37 
38             # Construct request URL
39             request_url = (
40                 "https://api-na.hosted.exlibrisgroup.com/almaws/v1/courses?"
41                 + "apikey="
42                 + secrets_local.prod_courses_api_key
43                 + "&q=name~"
44                 + semester
45                 + "*"
46                 + row["Dept"]
47                 + "*"
48                 + row["Course"]
49                 + "*"
50                 + row["Sec"]
51                 + "&format=json"
52             )
53 
54             response = requests.get(request_url).json()
55 
56             if int(response["total_record_count"]) > 1:
57                 for course in response["course"]:
58                     course_name = course["name"]
59                     result = bool(
60                         re.match(
61                             rf"^{semester}-[0\s]*{row['Dept']}\s*-[0\s]*{row['Course']}\s*-[0\s]*{row['Sec']}.+",
62                             course_name,
63                         )
64                     )
65                     if result:
66                         correct_course = course
67                         break
68             else:
69                 correct_course = response.get("course", [{}])[0]
70 
71             df.loc[index, "course_code"] = correct_course.get(
72                 "code", "Error finding course"
73             )
74             df.loc[index, "section"] = correct_course.get(
75                 "section", "Error finding course"
76             )
77             df.loc[index, "course_name"] = correct_course.get(
78                 "name", "Error finding course"
79             )
80             df.loc[index, "processing_department"] = correct_course.get(
81                 "processing_department", {}
82             ).get("desc", "Error finding processing department")
83 
84         output_path = os.path.join(
85             current_app.config["DOWNLOAD_FOLDER"], "Updated_Barnes_and_Noble.xlsx"
86         )
87         df.to_excel(output_path, index=False)
88         return output_path
89 

File: app/barnes_and_noble/requirements.txt
1 Flask==2.0.2
2 pandas==2.0.3
3 Requests==2.32.3
4 Werkzeug==2.0.3
5 

File: app/barnes_and_noble/routes.py
1 from flask import (
2     Blueprint,
3     request,
4     redirect,
5     url_for,
6     send_file,
7     current_app,
8     render_template,
9 )
10 from werkzeug.utils import secure_filename
11 import os
12 from .barnes_and_noble import OverlapAnalysis
13 
14 barnes_and_noble_blueprint = Blueprint("barnes_and_noble", __name__)
15 
16 
17 @barnes_and_noble_blueprint.route("/upload", methods=["POST"])
18 def upload_file():
19     if "file" not in request.files:
20         return redirect(url_for("main.error"))
21     file = request.files["file"]
22     if file.filename == "":
23         return redirect(url_for("main.error"))
24     filename = secure_filename(file.filename)
25     file_path = os.path.join(current_app.config["UPLOAD_FOLDER"], filename)
26     file.save(file_path)
27     analysis = OverlapAnalysis(file_path)
28     output_path = analysis.process()
29     return send_file(output_path, as_attachment=True)
30 
31 
32 @barnes_and_noble_blueprint.route("/", methods=["GET"])
33 def index():
34     return render_template("barnes_and_noble.html")
35 

File: app/bib_2_holdings_541/__init__.py
1 from .routes import blueprint_541
2 

File: app/bib_2_holdings_541/bib_2_holdings_541.py
1 import os
2 import pandas as pd
3 import re
4 from flask import (
5     Blueprint,
6     request,
7     redirect,
8     url_for,
9     send_file,
10     current_app,
11     render_template,
12 )
13 from werkzeug.utils import secure_filename
14 import io
15 from io import BytesIO
16 import zipfile
17 import dotenv
18 import os
19 from dotenv import load_dotenv
20 import json
21 import requests
22 import time
23 import pymarc as pym
24 import _elementtree as et
25 
26 
27 def zip_files(filenames):
28     memory_file = BytesIO()
29     with zipfile.ZipFile(memory_file, "w", zipfile.ZIP_DEFLATED) as zf:
30         for filename in filenames:
31             data = open(filename, "rb").read()
32             zf.writestr(os.path.basename(filename), data)
33     memory_file.seek(0)
34     return memory_file
35 
36 
37 class Bib2Holdings541:
38     def __init__(self, file_path):
39         self.file_path = file_path
40 
41         self.sandbox_bib_api_key = json.loads(os.getenv("sandbox_bib_api_key"))
42         self.analytics_api_key = json.loads(os.getenv("analytics_api_key"))
43         self.bib_url = json.loads(os.getenv("bib_url"))
44         self.errorCount = 0
45         # mismatchCount = 0
46         self.successCount = 0
47 
48         self.count_file = io.BytesIO()
49 
50         self.output_file = io.BytesIO()
51         self.output_file.write(
52             '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><holdings>'
53         )
54         self.error_file = io.BytesIO()
55 
56     def zip_files(filenames):
57         memory_file = BytesIO()
58         with zipfile.ZipFile(memory_file, "w", zipfile.ZIP_DEFLATED) as zf:
59             for filename in filenames:
60                 data = open(filename, "rb").read()
61                 zf.writestr(os.path.basename(filename), data)
62         memory_file.seek(0)
63         return memory_file
64 
65     def process(self):
66         mappings = self.getLocations()
67         bibList = []
68         bibListCounter = 0
69         with open(self.filepath, "rb") as file1:
70             for line in file1:
71                 line = line.decode("utf-8")
72                 line = line.replace("\r\n", "")
73                 bibList.append(line)
74                 bibListCounter += 1
75 
76         print("Number of bib records in input file: " + str(bibListCounter) + "\n")
77 
78         headers = {"Content-Type": "application/xml"}
79 
80         # count_file = open('Success and Error Counts.txt', 'w+')
81         # output_file = open("Output/updated_holdings.xml", "w+")
82         # output_file.write('<?xml version="1.0" encoding="UTF-8" standalone="yes"?><holdings>')
83         # error_file = open("Output/records_with_errors.txt", "w+")
84         fiveFortyOneCount = 0
85         for mms_id in bibList:
86             print("MMS ID: " + str(mms_id))
87 
88             bib_url = self.bib_url + str(mms_id) + "?apikey=" + self.sandbox_bib_api_key
89 
90             holdings_url = (
91                 self.bib_url
92                 + str(mms_id)
93                 + "/holdings?apikey="
94                 + self.sandbox_bib_api_key
95             )
96 
97             print(bib_url + "\n")
98             print("\n" + holdings_url + "\n")
99             bib_record = requests.get(bib_url)
100             bib_record_str = bib_record.content.decode("utf-8")
101             print("\nBib record: " + bib_record.text + "\n")
102             attached_holdings = requests.get(holdings_url)
103 
104             attached_holdings_str = attached_holdings.content.decode("utf-8")
105             print("\nHoldings: " + attached_holdings_str + "\n")
106 
107             # Python 2
108 
109             # unicode_bib_record = unicode(attached_holdings_str)
110 
111             # Python 3
112 
113             unicode_bib_record = str(bib_record_str)
114             if re.search("<errorsExist>true</errorsExist>", unicode_bib_record):
115                 self.error_file.write("MMS ID " + mms_id + " not in system\n")
116                 self.errorCount += 1
117                 print("MMS ID " + mms_id + " not in system\n")
118                 continue
119 
120             holdings_count_match = re.search(
121                 r'holdings\stotal_record_count\="(\d+)"', attached_holdings_str
122             )
123             holdingsCount = int(holdings_count_match.group(1))
124 
125             if holdingsCount == 0:
126                 self.error_file.write("No holdings for MMS ID" + mms_id + "\n")
127                 print("No holdings for MMS ID" + mms_id + "\n")
128                 errorCount += 1
129                 continue
130 
131             # Python 2
132             # unicode_attached_holdings = unicode(attached_holding_str)
133 
134             # Python 3
135 
136             unicode_attached_holdings = str(attached_holdings_str)
137 
138             # print(unicode_attached_holdings)
139             # sys.exit()
140 
141             bib_record = pym.parse_xml_to_array(io.StringIO(unicode_bib_record))
142 
143             tree_orig = et.ElementTree(et.fromstring(attached_holdings_str))
144 
145             root_orig = tree_orig.getroot()
146 
147             # for element in root_orig.iter():
148             #    print(element.text)
149             #    sys.exit()
150             holdings_xml_string = (
151                 '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><holdings>'
152             )
153             for attached_holding in root_orig.findall(".//holding"):
154                 print("\n\nHolding: " + str(et.tostring(attached_holding)) + "\n")
155 
156                 holding_id = attached_holding.find("holding_id").text
157 
158                 print("\nHolding ID: " + str(holding_id) + "\n")
159 
160                 try:
161                     holding_record = requests.get(
162                         self.bib_url
163                         + str(mms_id)
164                         + "/holdings/"
165                         + str(holding_id)
166                         + "?apikey="
167                         + self.sandbox_bib_api_key
168                     )
169 
170                 except:
171                     print(
172                         "Can't retrieve holding with MMS ID: "
173                         + mms_id
174                         + " and holding ID: "
175                         + str(holding_id)
176                         + "\n"
177                     )
178                     self.error_file.write(
179                         "Can't retrieve holding with MMS ID: "
180                         + mms_id
181                         + " and holding ID: "
182                         + str(holding_id)
183                         + "\n"
184                     )
185                     self.errorCount += 1
186                     continue
187                 holding_string = holding_record.content.decode("utf-8")
188 
189                 holding_string = holding_string.replace(
190                     '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>', ""
191                 )
192 
193                 holdings_xml_string += holding_string
194 
195             holdings_xml_string += "</holdings>"
196 
197             # Python 2
198             # unicode_holdings_xml_string = unicode(holdings_xml_string, 'utf-8')
199 
200             # Python 3
201             unicode_holdings_xml_string = holdings_xml_string
202 
203             b = 1
204 
205             tree = et.ElementTree(et.fromstring(unicode_holdings_xml_string))
206             root = tree.getroot()
207 
208             countList = []
209             for five_forty_one in bib_record[0].get_fields("541"):
210                 found541 = False
211                 fiveFortyOneCount += 1
212                 subfield_3 = five_forty_one["3"]
213                 # if not subfield_3 in all541:
214                 #     all541.append(subfield_3)
215                 print("\n\nRepeated 541 subfield 3: \n" + str(subfield_3) + "\n\n")
216                 print("\n\n541: \n" + str(five_forty_one) + "\n\n")
217 
218                 try:
219                     location_541_match = re.search(
220                         r"^(.+Library|TISCH|HHSL|MUSIC|GINN|VET|Tisch|Ginn|Music|Vet|Hirsh|EUR)[ ]?(.+)?([ ]print)?[ ]+copy",
221                         subfield_3,
222                         re.IGNORECASE,
223                     )
224                     library_541 = location_541_match.group(1)
225                     library_541 = library_541.encode("utf-8", "replace").decode()
226                 except:
227                     print(
228                         "Library or location in 541 for MMS ID: "
229                         + str(mms_id)
230                         + " and holding ID: "
231                         + str(holding_id)
232                         + " is not retrievable or is not an expected value\n"
233                     )
234                     self.error_file.write(
235                         "Library or location in 541 for MMS ID: "
236                         + str(mms_id)
237                         + " is not retrievable or is not an expected value\n"
238                     )
239                     errorCount += 1
240                     continue
241 
242                 print(
243                     "\nLibrary: <boundary>"
244                     + library_541
245                     + "</boundary>"
246                     + "Data type: "
247                     + str(type(library_541))
248                     + "\n"
249                 )
250 
251                 location_541 = ""
252                 library = ""
253                 location = ""
254                 location_code = ""
255                 location_description = ""
256                 location_suffix = ""
257                 try:
258                     location_541 = location_541_match.group(2)
259                     location_541 = location_541.encode("utf-8", "replace")
260                 except:
261                     location_541 = ""
262 
263                 try:
264                     location_541 = location_541.decode("utf-8")
265                 except:
266                     pass
267 
268                 if (
269                     library_541 == "Tisch Library"
270                     or str(library_541) == "TISCH"
271                     or str(library_541) == "Tisch"
272                 ):
273                     library = "TISCH"
274                 elif (
275                     str(library_541) == "Ginn Library"
276                     or str(library_541) == "GINN"
277                     or str(library_541) == "Ginn"
278                 ):
279                     library = "GINN"
280                 elif (
281                     library_541 == "Lilly Music Library"
282                     or str(library_541) == "MUSIC"
283                     or str(library_541) == "Music"
284                 ):
285                     library = "MUSIC"
286                 elif (
287                     library_541 == "W. Van Alan Clark, Jr. Library"
288                     or str(library_541) == "SMFA"
289                 ):
290                     library = "SMFA"
291                 elif (
292                     library_541 == "Webster Family Library"
293                     or str(library_541) == "VET"
294                     or str(library_541) == "Vet"
295                 ):
296                     library = "VET"
297                 elif (
298                     library_541 == "Hirsch Health Sciences Library"
299                     or str(library_541) == "Hirsh Health Sciences Library"
300                     or str(library_541) == "HHSL"
301                     or str(library_541) == "Hirsh"
302                 ):
303                     library = "HIRSH"
304                 elif library_541 == "EUR":
305                     library = "Talloires"
306                 else:
307                     print(
308                         "Library in 541 for MMS ID: "
309                         + str(mms_id)
310                         + " is not retrievable or is not an expected value\n"
311                     )
312                     self.error_file.write(
313                         "Library in 541 for MMS ID: "
314                         + str(mms_id)
315                         + " is not retrievable or is not an expected value\n"
316                     )
317                     errorCount += 1
318                     continue
319 
320                 print("\nLibrary for 852 from 541: " + library + "\n")
321                 print("Location_541:               " + str(location_541) + "\n")
322 
323                 for full_holding in root.findall("holding"):
324                     print(
325                         "\nHolding record " + str(b) + ": \n" + str(full_holding) + "\n"
326                     )
327                     b += 1
328                     holding_id = full_holding.find("holding_id").text
329                     c = 0
330                     print("541: \n" + str(bib_record))
331 
332                     holding = pym.parse_xml_to_array(
333                         io.StringIO(et.tostring(full_holding).decode("utf-8"))
334                     )[0]
335 
336                     full_holding_string = et.tostring(full_holding)
337 
338                     foundLocation = False
339 
340                     library_locations = mappings[library]
341 
342                     for dict_location in library_locations:
343                         if location_541.lower() in dict_location.lower():
344                             location_description = dict_location
345                             foundLocation = True
346                             break
347 
348                     if str(location_541) != "" and foundLocation == True:
349                         location_code = mappings[library][location_description]
350 
351                     elif (
352                         str(location_541) == ""
353                         and holding["852"]["b"] == library
354                         and library not in countList
355                     ):
356                         location_code = holding["852"]["c"]
357                         countList.append(library)
358                         foundLocation == True
359                     # elif holdingsCount > 1:
360                     #     print("No location specified in 541, but more than one holding in record for " + str(mms_id) + "\n")
361                     #     error_file.write("No location specified in 541, but more than one holding in record for " + str(mms_id) + "\n")
362                     #     errorCount += 1
363                     #     continue
364 
365                     # library_and_location = library + location_suffix
366 
367                     # print("Library and location: " + library_and_location + "\n\n")
368 
369                     if foundLocation == True:
370                         print("Location code: " + location_code + "\n")
371                         if holding["852"]["c"] == location_code:
372                             found541 = True
373                             success = self.update_holding(
374                                 holding,
375                                 holding_id,
376                                 full_holding_string,
377                                 five_forty_one,
378                                 mms_id,
379                             )
380                             # matched541.append(subfield_3)
381                             if success == True:
382                                 successCount += 1
383                             else:
384                                 print(
385                                     "Couldn't write holding "
386                                     + str(holding_id)
387                                     + " for "
388                                     + str(mms_id)
389                                     + "to Alma via the API.\n"
390                                 )
391                                 self.error_file.write(
392                                     "Couldn't write holding "
393                                     + str(holding_id)
394                                     + " for "
395                                     + str(mms_id)
396                                     + "to Alma via the API.\n"
397                                 )
398                                 errorCount += 1
399                                 continue
400 
401                     else:
402                         # print("Could not match location field from 541 to a location in Alma for " + str(mms_id) + ". This might be because there is no location in the 541, there's no matching library, or there's a typo in the 541 location.\n")
403                         # error_file.write("Could not match location field from 541 to a location in Alma for " + str(mms_id) + ". This might be because there is no location in the 541, there's no matching library, or there's a typo in the 541 location.\n")
404                         # mismatchCount += 1
405                         continue
406 
407                 if found541 == False:
408                     print(
409                         "The 541 for bib record "
410                         + str(mms_id)
411                         + " could not match to a holding location.\n"
412                     )
413                     self.error_file.write(
414                         "The 541 for bib record "
415                         + str(mms_id)
416                         + " could not match to a holding location.\n"
417                     )
418                     errorCount += 1
419 
420                 # Python 2
421 
422                 # holding = pym.parse_xml_to_array(io.StringIO(unicode(et.tostring(full_holding))))[0]
423 
424                 # Python 3
425 
426         print(
427             "Number of 541s:                                                       "
428             + str(fiveFortyOneCount)
429             + "\n"
430         )
431         self.count_file.write(
432             "Number of 541s:                                            "
433             + str(fiveFortyOneCount)
434             + "\n"
435         )
436         print(
437             "Records successfully updated:                                         "
438             + str(successCount)
439             + "\n"
440         )
441         self.count_file.write(
442             "Records successfully updated:                              "
443             + str(successCount)
444             + "\n"
445         )
446         print(
447             "Records that couldn't be updated.  Check error file:                  "
448             + str(errorCount)
449             + "\n"
450         )
451         self.count_file.write(
452             "Records that couldn't be updated.  Check error file:       "
453             + str(errorCount)
454             + "\n"
455         )
456         # print("Matching errors between 541 and holdings. Check error file:           " + str(mismatchCount) + "\n")
457         # count_file.write("atching errors between 541 and holdings. Check error file: " + str(mismatchCount) + "\n")
458 
459         self.count_file.seek(0)
460         self.output_file.seek(0)
461         self.error_file.seek(0)
462 
463         # Step 2: Create ZIP Archive in Memory
464         zip_buffer = io.BytesIO()
465         with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
466             zip_file.writestr("Count File.txt", self.count_file.getvalue())
467             zip_file.writestr("Errors.txt", self.error_file.getvalue())
468             zip_file.writestr("Output File.xml", self.output_file.getvalue())
469 
470         zip_buffer.seek(0)
471 
472         # Step 3: Return ZIP File for Download
473         return send_file(
474             zip_buffer,
475             mimetype="application/zip",
476             as_attachment=True,
477             download_name="rollup_files.zip",
478         )
479 
480     def update_holding(
481         holding, holding_id, full_holding_string, five_forty_one, mms_id, self
482     ):
483         holding.add_field(five_forty_one)
484         print("Holding with new field: \n" + str(holding) + "\n\n\n")
485         updated_holding = pym.record_to_xml(holding).decode("utf-8")
486 
487         full_holding_string = full_holding_string.decode("utf-8")
488 
489         full_updated_holding = re.sub(
490             r"<record>(.+)</record>", updated_holding, full_holding_string
491         )
492 
493         print("Updated XML Holding Record: \n" + full_updated_holding + "\n")
494 
495         full_updated_holding = full_updated_holding.replace(
496             '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>', ""
497         )
498 
499         # success = True
500 
501         # faulty_xml = "<holding></holding>"
502         #
503         # # full_holdings_xml = root.find('holding/holding_id=')
504         #
505         #
506         response = requests.put(
507             self.bib_url
508             + str(mms_id)
509             + "/holdings/"
510             + str(holding_id)
511             + "?apikey="
512             + secrets_local.bib_api_key,
513             data=full_updated_holding,
514             headers=headers,
515         )
516         #
517         time.sleep(2)
518         print(response.content)
519         # #
520         # #
521         # # # response = requests.put("https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/" + str(mms_id) + "/holdings/" + str(holding_id) + "?apikey=", data=full_updated_holding, headers=headers)
522         # # #
523         # # # print(response.content)
524         if re.search("<errorsExist>true</errorsExist>", response.content):
525             print("Couldn't write back to Alma for MMS ID: " + mms_id + "\n")
526             self.error_file.write(
527                 "Couldn't write back to Alma for MMS ID: " + mms_id + "\n"
528             )
529             success = False
530         else:
531             self.output_file.write(
532                 "<MMS_ID_"
533                 + mms_id
534                 + ">"
535                 + full_updated_holding
536                 + "</MMS_ID_"
537                 + mms_id
538                 + ">"
539             )
540 
541             success = True
542 
543         # print(response.content)
544         #
545         # print(success)
546         #
547         # sys.exit()
548         return success
549 
550     def getLocations():
551         url = (
552             "https://api-na.hosted.exlibrisgroup.com/almaws/v1/analytics/reports?apikey="
553             + secrets_local.analytics_api_key
554         )
555         limit = "&limit=1000"
556         format = "&format=xml"
557         path = "&path=%2Fshared%2FTufts+University%2FReports%2FCataloging%2FAdding+541+to+Holdings+Records%2FLocation+Name-Location+Code"
558 
559         report = requests.get(url + format + path + limit)
560 
561         # print("\nReport Content: \n" + report.content)
562 
563         report_outfile = open("Output/list of codes and locations.xml", "w+")
564 
565         # report_str = report.content.decode('utf-8')
566         report_outfile.write(str(report.content))
567 
568         # print("\n\nReport: \n" + report.content)
569 
570         report_outfile.close()
571 
572         tree = et.ElementTree(et.fromstring(report.content))
573 
574         # print("\nTree: " + tree.text + "\n")
575 
576         root = tree.getroot()
577 
578         print("\nRoot: \n" + str(root.text) + "\n")
579 
580         reportDict = {}
581         # for element in root.iter('{urn:schemas-microsoft-com:xml-analysis:rowset}Row'):
582         # print("\n\nAll Elements: \n" + str(list(root.iter())))
583 
584         for element in root.iter():
585             library = ""
586             code = ""
587             description = ""
588             if re.match(r".*Row", element.tag):
589                 for sub_element in element.iter():
590                     if re.match(r".*Column2", sub_element.tag):
591                         code = sub_element.text
592                     if re.match(r".*Column3", sub_element.tag):
593                         description = sub_element.text
594                     elif re.match(r".*Column1", sub_element.tag):
595                         library = sub_element.text
596 
597             if library in reportDict:
598                 reportDict[library][description] = code
599             else:
600                 reportDict[library] = {}
601                 reportDict[library][description] = code
602 
603         # for c in reportDict:
604         # 	c = c.decode('ascii')
605         # 	for d in reportDict[c]:
606         # 		reportDict[c][d] = reportDict[c][d].decode('ascii')
607         for i in reportDict:
608             for j in reportDict[i]:
609                 print(
610                     "Library: "
611                     + str(i)
612                     + "; Description: "
613                     + str(j)
614                     + "; Code: "
615                     + str(reportDict[i][j])
616                     + "\n"
617                 )
618         return reportDict
619 

File: app/bib_2_holdings_541/routes.py
1 from flask import (
2     Blueprint,
3     request,
4     redirect,
5     url_for,
6     send_file,
7     current_app,
8     render_template,
9 )
10 from werkzeug.utils import secure_filename
11 import os
12 from app.bib_2_holdings_541.bib_2_holdings_541 import Bib2Holdings541
13 
14 
15 blueprint_541 = Blueprint("bib_2_holdings_541", __name__)
16 
17 
18 @blueprint_541.route("/upload", methods=["POST"])
19 def upload_file():
20     if request.method == "POST":
21         # Retrieve the file from the form field named 'file'
22         file = request.files.get("file")
23         if not file:
24             return "No file provided", 400
25 
26         # Optional: Check for additional form fields, e.g., a checkbox for ISBN processing
27         isbn_bool = request.form.get("isbn_bool", "false").lower() == "true"
28 
29         bib2Holdings541 = Bib2Holdings541()
30         return bib2Holdings541.process()
31     else:
32         # Render a simple upload form (ensure you have an 'upload.html' template)
33         return render_template("upload.html")
34 
35 
36 @blueprint_541.route("/", methods=["GET"])
37 def index():
38     return render_template("bib_2_holdings_541.html")
39 

File: app/main/__init__.py
1 # Import the main blueprint from routes.py
2 from .routes import main_blueprint
3 

File: app/main/routes.py
1 from flask import Blueprint, render_template
2 
3 # Define the main blueprint
4 main_blueprint = Blueprint("main", __name__)
5 
6 
7 # Define the route for the main page
8 @main_blueprint.route("/")
9 def index():
10     """
11     Render the index.html template as the main page.
12     """
13     return render_template("index.html")
14 

File: app/p_and_e_rollup_match/__init__.py
1 from .routes import p_and_e_blueprint
2 

File: app/p_and_e_rollup_match/p_and_e_rollup_match.py
1 import os
2 import pandas as pd
3 import re
4 from flask import (
5     Blueprint,
6     request,
7     redirect,
8     url_for,
9     send_file,
10     current_app,
11     render_template,
12 )
13 from werkzeug.utils import secure_filename
14 import io
15 from io import BytesIO
16 import zipfile
17 
18 
19 def zip_files(filenames):
20     memory_file = BytesIO()
21     with zipfile.ZipFile(memory_file, "w", zipfile.ZIP_DEFLATED) as zf:
22         for filename in filenames:
23             data = open(filename, "rb").read()
24             zf.writestr(os.path.basename(filename), data)
25     memory_file.seek(0)
26     return memory_file
27 
28 
29 class ResourceMatch:
30     def __init__(self, file_path, isbn_bool):
31         self.file_path = file_path
32         self.isbn_bool = isbn_bool
33 
34     def process(self):
35         df = pd.read_excel(
36             self.file_path,
37             engine="openpyxl",
38             sheet_name="Matches with Multiple Resources",
39             dtype=str,
40         )
41         df = df.applymap(lambda x: str(x).replace('"', "") if isinstance(x, str) else x)
42 
43         df = df.applymap(lambda x: str(x).replace('"', "") if isinstance(x, str) else x)
44 
45         print(f"DataFrame shape before grouping: {df.shape}")
46         print(df.head())  # Display first few rows
47 
48         df["ISSN"] = df["ISSN"].apply(lambda x: re.sub(r"\s+", r"; ", x))
49 
50         df = df["ISSN"].str.split(";").explode().reset_index(drop=True)
51 
52         if self.isbn_bool:
53             df["ISBN"] = df["ISBN"].apply(lambda x: re.sub(r"\s+", r"; ", x))
54 
55             df["ISBN(13)"] = df["ISBN(13)"].apply(lambda x: re.sub(r"\s+", r"; ", x))
56 
57         rollup_columns = []
58 
59         if self.isbn_bool:
60             rollup_columns = [
61                 "Collection",
62                 "Interface",
63                 "Portfolio ID",
64                 "Coverage",
65                 "Embargo",
66                 "Resource Scope",
67                 "Linked To CZ",
68                 "Open Access",
69                 "Access Type",
70                 "Is Active",
71                 "ISBN",
72                 "ISBN(13)",
73                 "ISBN(Matching Identifier)",
74             ]
75 
76             rollup_columns_sum = [
77                 "Link resolver usage (access)",
78                 "Link resolver usage (appearance)",
79             ]
80 
81         else:
82             rollup_columns = [
83                 "Collection",
84                 "Interface",
85                 "Portfolio ID",
86                 "Coverage",
87                 "Embargo",
88                 "Resource Scope",
89                 "Linked To CZ",
90                 "Open Access",
91                 "Access Type",
92                 "Is Active",
93             ]
94 
95             rollup_columns_sum = [
96                 "Link resolver usage (access)",
97                 "Link resolver usage (appearance)",
98             ]
99         df[rollup_columns_sum] = df[rollup_columns_sum].fillna(0)
100         df[rollup_columns_sum] = df[rollup_columns_sum].astype(int)
101 
102         groupby_columns = []
103         for column in df.columns:
104             if column not in rollup_columns and column not in rollup_columns_sum:
105                 groupby_columns.append(column)
106 
107         print(groupby_columns)
108 
109         print(rollup_columns)
110 
111         print(rollup_columns_sum)
112         df.fillna("", inplace=True)
113         print(f"Actual DataFrame columns: {df.columns.tolist()}")
114 
115         # Create aggregation dictionary dynamically
116         agg_dict = {
117             col: lambda x: "; ".join(set(x.astype(str))) for col in rollup_columns
118         }
119 
120         sum_dict = {col: lambda x: x.astype(int).sum() for col in rollup_columns_sum}
121         print(agg_dict)
122 
123         print(sum_dict)
124 
125         # Merge both aggregation strategies
126         agg_dict.update(sum_dict)
127         # Apply groupby and aggregation
128         df_grouped = df.groupby(groupby_columns, as_index=False).agg(agg_dict)
129         df_grouped = df_grouped[df.columns]
130         print(df_grouped)
131 
132         df2 = pd.read_excel(
133             self.file_path,
134             engine="openpyxl",
135             sheet_name="Matches with Single Resource",
136             dtype=str,
137         )
138         df[rollup_columns_sum] = df[rollup_columns_sum].fillna(0)
139         df[rollup_columns_sum] = df[rollup_columns_sum].astype(int)
140 
141         isbn_columns = ["ISBN", "ISBN(13)", "ISBN(Matching Identifier)"]
142 
143         single_match_groupby_columns = (
144             groupby_columns + rollup_columns + rollup_columns_sum
145         )
146 
147         if self.isbn_bool:
148             isbn_dict = {
149                 col: lambda x: "; ".join(set(x.astype(str))) for col in isbn_columns
150             }
151             df2_grouped = df2.groupby(single_match_groupby_columns, as_index=False).agg(
152                 isbn_dict
153             )
154             df2_grouped = df2_grouped[df2.columns]
155 
156             df2 = df2_grouped
157 
158         # Remove double quotes from all values in the DataFrame
159         df2 = df2.applymap(lambda x: x.replace('"', "") if isinstance(x, str) else x)
160 
161         # Append df2 to df
162         df_combined = pd.concat([df_grouped, df2], ignore_index=True)
163 
164         no_match_df = pd.read_excel(
165             self.file_path,
166             engine="openpyxl",
167             sheet_name="No Matches or No Resources",
168             dtype=str,
169         )
170         no_match_df = no_match_df.applymap(
171             lambda x: str(x).replace('"', "") if isinstance(x, str) else x
172         )
173 
174         try:
175             no_match_df = no_match_df.rename(columns={"MMS Id": "MMS ID"})
176 
177         except:
178             no_match_df = no_match_df
179 
180         print(no_match_df)
181 
182         no_match_df = no_match_df.fillna("")
183         if self.isbn_bool:
184             no_match_group_by_columns = []
185             for column in no_match_df.columns:
186                 if column != "ISBN(Matching Identifier)":
187                     no_match_group_by_columns.append(column)
188             print(no_match_group_by_columns)
189             isbn_dict_2 = {
190                 col: lambda x: "; ".join(set(x.astype(str)))
191                 for col in ["ISBN(Matching Identifier)"]
192             }
193 
194             no_match_df["ISBN(Matching Identifier)"] = no_match_df[
195                 "ISBN(Matching Identifier)"
196             ].fillna("")
197             no_match_df["ISBN(Matching Identifier)"] = no_match_df[
198                 "ISBN(Matching Identifier)"
199             ].astype(str)
200 
201             print(isbn_dict_2)
202 
203             # Debug print: Check columns
204             print("Available columns in no_match_df:", no_match_df.columns.tolist())
205             print("Grouping by columns:", no_match_group_by_columns)
206 
207             # Ensure grouping columns exist
208             no_match_group_by_columns = [
209                 col for col in no_match_group_by_columns if col in no_match_df.columns
210             ]
211             print("Updated grouping columns:", no_match_group_by_columns)
212 
213             # Ensure ISBN(Matching Identifier) is not empty
214             no_match_df = no_match_df[
215                 no_match_df["ISBN(Matching Identifier)"].notna()
216                 & (no_match_df["ISBN(Matching Identifier)"] != "")
217             ]
218             if no_match_df.empty:
219                 print(
220                     "⚠️ Warning: no_match_df is empty after removing empty ISBN(Matching Identifier). Skipping grouping."
221                 )
222             else:
223                 no_match_df["ISBN(Matching Identifier)"] = no_match_df[
224                     "ISBN(Matching Identifier)"
225                 ].astype(str)
226                 no_match_df_grouped = no_match_df.groupby(
227                     no_match_group_by_columns, as_index=False
228                 ).agg(isbn_dict_2)
229 
230                 print("After grouping:", no_match_df_grouped)
231 
232                 no_match_df = no_match_df_grouped
233             # no_match_df_grouped = no_match_df.groupby(no_match_group_by_columns, as_index=False).agg(isbn_dict_2)
234             #
235             # print("just after grouping")
236             #
237             # print(no_match_df_grouped)
238             # no_match_df_grouped = no_match_df_grouped[no_match_df.columns]
239             #
240             # print("after matching columns")
241             # print(no_match_df_grouped)
242             #
243             #
244             # no_match_df_grouped = no_match_df_grouped[no_match_df.columns]
245             #
246             # print(no_match_df_grouped)
247             # no_match_df = no_match_df_grouped
248             #
249             # print(no_match_df)
250         df_combined = pd.concat([df_grouped, df2], ignore_index=True)
251         # Write the combined dataframe to an in-memory Excel file
252         output_combined = io.BytesIO()
253         df_combined.to_excel(output_combined, index=False)
254         output_combined.seek(0)
255 
256         output_no_match = io.BytesIO()
257 
258         no_match_df.to_excel(output_no_match, index=False)
259 
260         output_no_match.seek(0)
261 
262         # Step 2: Create ZIP Archive in Memory
263         zip_buffer = io.BytesIO()
264         with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
265             zip_file.writestr(
266                 "Merged Single and Multiple Resources with Rolled up Multiple Resources.xlsx",
267                 output_combined.getvalue(),
268             )
269             zip_file.writestr("No Match.xlsx", output_no_match.getvalue())
270 
271         zip_buffer.seek(0)
272 
273         # Step 3: Return ZIP File for Download
274         return send_file(
275             zip_buffer,
276             mimetype="application/zip",
277             as_attachment=True,
278             download_name="rollup_files.zip",
279         )
280 

File: app/p_and_e_rollup_match/routes.py
1 from flask import (
2     Blueprint,
3     request,
4     redirect,
5     url_for,
6     send_file,
7     current_app,
8     render_template,
9 )
10 from werkzeug.utils import secure_filename
11 import os
12 from .p_and_e_rollup_match import ResourceMatch
13 
14 p_and_e_blueprint = Blueprint("p_and_e", __name__)
15 
16 
17 @p_and_e_blueprint.route("/upload", methods=["POST"])
18 def upload_file():
19     if request.method == "POST":
20         # Retrieve the file from the form field named 'file'
21         file = request.files.get("file")
22         if not file:
23             return "No file provided", 400
24 
25         # Optional: Check for additional form fields, e.g., a checkbox for ISBN processing
26         isbn_bool = request.form.get("isbn_bool", "false").lower() == "true"
27 
28         resource_match = ResourceMatch(file, isbn_bool)
29         return resource_match.process()
30     else:
31         # Render a simple upload form (ensure you have an 'upload.html' template)
32         return render_template("upload.html")
33 
34 
35 @p_and_e_blueprint.route("/", methods=["GET"])
36 def index():
37     return render_template("bib_2_holdings_541.html")
38 

File: app/routes.py
1 from flask import request, render_template, Blueprint, g
2 import redis
3 import json
4 import os
5 import app.p_and_e_rollup_match.p_and_e_rollup_match
6 import app.barnes_and_noble.barnes_and_noble
7 import app.bib_2_holdings_541.bib_2_holdings_541
8 
9 
10 main = Blueprint("main", __name__)
11 
12 
13 @main.route("/resource_match", methods=["GET", "POST"])
14 def resource_match():
15     return render_template("resource_match.html")
16 

File: app/static/styles.css
1 @property --tufts-blue {
2     syntax: "<color>";
3     inherits: false;
4     initial-value: #3172AE;
5   }
6   @property --heading-blue {
7     syntax: "<color>";
8     inherits: false;
9     initial-value: #002E6D;
10   }
11   @property --light-gray{
12     syntax: "<color>";
13     inherits: false;
14     initial-value: #F2F2F2;
15   }
16 
17 body {
18     font-family: Arial, sans-serif;
19     margin: 0;
20 }
21 header{
22   background-color: var(--tufts-blue);
23   width: 100%;
24   
25 }
26 
27 form{
28   display: flex;
29   flex-flow: row wrap;
30   align-items: center;
31 }
32 header .logo{
33   padding: 1em;
34   font-size: 1.5em;
35   font-weight: bold;
36   color: white;
37 }
38 
39 header .logo a{
40   padding: .3em;
41   font-size: .75em;
42   font-weight: bold;
43   color: white;
44 }
45 
46 header .logo .subtext{
47   font-size: 1em;
48   font-weight: initial;
49   color: white;
50 }
51 
52 .content{
53     margin: 0 2em;
54 }
55 h1, h2{
56   color: var(--heading-blue);
57 }
58 h1{
59   margin-top: 1em;
60 }
61 h2{
62  margin-top: 2em;
63 }
64 .vhide{
65     position: absolute !important;
66     overflow: hidden !important;
67     clip: rect(1px, 1px, 1px, 1px);
68     width: 1px;
69     height: 1px;
70     word-wrap: normal;
71 }
72 
73 #hourglass {
74   position: fixed;
75   top: 50%;
76   left: 50%;
77   transform: translate(-50%, -50%);
78   z-index: 9999;
79 }
80 
81 label{
82 	width:5%;
83 }
84 table{
85  @media all and (max-width: 500px){
86     width: 100%;
87  }
88  width: 60%;
89  
90 }
91 
92 
93 table td{
94     padding: 0.5em;
95 
96 }
97 table th{
98     border-bottom: 1px solid gray;
99 }
100 table tr:nth-of-type(even){
101     background-color: var(--light-gray);
102 }
103 
104 #footer{height: 110px; background: repeat-x top left #427dc1;}
105 #footer a {color:white}
106 #float-first {    float: left; clear: none;}
107 				#float-second {    float: left;clear: none;}
108 button{
109     background-color: darkblue;
110     color: white;
111     padding: 0.5em;
112     border: none;
113     border-radius: 0.25em;
114 }
115 input[type="file"]{
116     padding: 0.5em;
117     background-color: var(--light-gray);
118 }
119 #hourglass {
120     position: fixed;
121     top: 50%;
122     left: 50%;
123     transform: translate(-50%, -50%);
124     z-index: 9999;
125 }
126 
127 .input{
128 	float:left;
129 	width:15%;
130 	clear:both;
131 }
132 .spinner {
133     border: 16px solid #f3f3f3;
134     border-top: 16px solid #3498db;
135     border-radius: 50%;
136     width: 120px;
137     height: 120px;
138     animation: spin 2s linear infinite;
139 }
140 @keyframes spin {
141     0% { transform: rotate(0deg); }
142     100% { transform: rotate(360deg); }
143 }
144 

File: app/templates/barnes_and_noble.html
1 {% extends "base.html" %}
2 {% block content %}
3     <h1>Upload an Excel file for Barnes and Noble Overlap Analysis</h1>
4     <form action="/barnes_and_noble/upload" method="post" enctype="multipart/form-data" onsubmit="submitFormWithFetch(event, this)">
5         <input type="file" name="file" required>
6         <button type="submit">Upload</button>
7     </form>
8 {% endblock %}
9 

File: app/templates/base.html
1 <!DOCTYPE html>
2 <html lang="en">
3 <head>
4     <meta charset="UTF-8">
5     <meta name="viewport" content="width=device-width, initial-scale=1.0">
6     <title>Self Service Portal</title>
7     <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
8 
9     <link rel="stylesheet" href="{{ url_for('static', filename='styles.css') }}"> 
10     <script src="https://cdnjs.cloudflare.com/ajax/libs/xlsx/0.17.0/xlsx.full.min.js"></script>
11 
12     <script>
13         async function submitFormWithFetch(event, form) {
14             event.preventDefault();  // Prevent normal form submission
15             showHourglass();
16 
17             let formData = new FormData(form);
18 
19             try {
20                 let response = await fetch(form.action, {
21                     method: "POST",
22                     body: formData
23                 });
24 
25                 if (!response.ok) throw new Error("Network response was not ok");
26 
27                 let blob = await response.blob();
28                 let filename = getFilenameFromResponse(response) || "download.xlsx";
29 
30                 let link = document.createElement("a");
31                 link.href = window.URL.createObjectURL(blob);
32                 link.download = filename;
33                 document.body.appendChild(link);
34                 link.click();
35                 document.body.removeChild(link);
36                 
37             } catch (error) {
38                 alert("Error downloading file: " + error.message);
39             } finally {
40                 hideHourglass();
41             }
42         }
43 
44         function showHourglass() {
45             $("#hourglass").show();
46         }
47 
48         function hideHourglass() {
49             $("#hourglass").hide();
50         }
51 
52         function getFilenameFromResponse(response) {
53             let disposition = response.headers.get("Content-Disposition");
54             if (disposition && disposition.includes("filename=")) {
55                 return disposition.split("filename=")[1].replace(/['"]/g, "");
56             }
57             return null;
58         }
59     </script>
60 </head>
61 <body>
62     <div id="hourglass" style="display: none;">
63         <div class="spinner"></div>
64     </div>
65     <header>
66         <div class="logo">Tufts Libraries&nbsp;&nbsp;<span class="subtext">Self Service Portal</span><p><a href="/">Home</a></p></div></div> 
67         
68     </header>
69     <div class="content">
70         {% block content %}{% endblock %}
71     </div>
72     <!-- <div id="footer">
73         <div>
74         <div id="float-first">
75         <img src="tufts-logo-univ-white.svg" class="footer" />
76         <br />
77         <span style="font-size: .9em">Copyright &copy;2013 <a href="http://www.tufts.edu">Tufts University</a> <br /><span style="color:white;">All Rights Reserved.</span></span>
78         </div>
79         
80         <div id="float-second">
81         <table id="footer_table" style="font-size: .9em" cellspacing="0">
82         
83                         <tr>
84                             <td>Ginn Library</td>
85         
86                             <td>
87                                 <a href="mailto:ginncirc@tufts.edu">ginncirc@tufts.edu</a>
88                             </td>
89         
90                             <td>617-627-3852</td>
91         
92                         </tr>
93                         <tr>
94                             <td>Hirsh Health Sciences Library</td>
95         
96                             <td>
97                                 <a href="mailto:hhsl@tufts.edu">hhsl@tufts.edu</a>
98                             </td>
99                             <td>617-636-6706</td>
100         
101                         </tr>
102                         <tr>
103                             <td>Lilly Music Library</td>
104         
105                             <td>
106                                 <a href="mailto:musiclib@tufts.edu">musiclib@tufts.edu</a>
107                             </td>
108                             <td>617-627-3594</td>
109         
110                         </tr>
111                         <tr>
112                             <td>SMFA Library</td>
113         
114                             <td>
115                                 <a href="mailto:smfalibrary@tufts.edu ">smfalibrary@tufts.edu</a>
116                             </td>
117                             <td>617-627-0080</td>
118         
119                         </tr>
120                         <tr>
121                             <td>Tisch Library</td>
122         
123                             <td>
124                                 <a href="mailto:tischfrontline@elist.tufts.edu"
125                                     >tischfrontline@elist.tufts.edu</a>
126                             </td>
127                             <td>617-627-3347</td>
128         
129                         </tr>
130                         <tr>
131                             <td>Webster Vet Library</td>
132         
133                             <td>
134                                 <a href="mailto:webvet@tufts.edu">webvet@tufts.edu</a>
135                             </td>
136                             <td>508-839-7957</td>
137         
138                         </tr>
139         
140                     </table>
141         
142         <br />
143         
144         </div>
145         </div></div> -->
146         
147 
148 </body>
149 </html>
150 

File: app/templates/bib_2_holdings_541.html
1 {% extends "base.html" %}
2 {% block content %}
3     <h1 style="color:red">ALMA SANDBOX</h1>
4     <h1>Bib 2 Holdings 541</h1>
5     <p>Upload a single column text file with each MMS on a separate line, of records for which you want to apply the bib 541 to the holding record.</p>
6     <form action="/bib_2_holdings_541/upload" method="post" enctype="multipart/form-data" onsubmit="submitFormWithFetch(event, this)">
7         <input type="file" name="file" required>
8         <button type="submit">Upload</button>
9     </form>
10 {% endblock %}
11 

File: app/templates/index.html
1 {% extends "base.html" %}
2 {% block content %}
3     <h1>Self Service Portal</h1>
4 
5     <p>This site contains scripts and processes that libraries use to help with workflows and analysis.  To access these functions, click on one of the links below.</p>
6     <ul><h3>Processes</h3>
7         <li><a href="{{ url_for('barnes_and_noble.index') }}">Barnes and Noble Course Matching</a></li>
8         <li><a href="{{ url_for('p_and_e.index')}}">Physical and Electronic Processing Overlap Analysis</a></li>
9         <li><a href="{{ url_for('bib_2_holdings_541.index')}}">Bib To Holdings 541</a></li>
10 
11 
12     </ul>
13 {% endblock %}
14 

File: app/templates/p_and_e_rollup_match.html
1 {% extends "base.html" %}
2 {% block content %}
3     <h1>Upload a File for P and E Rollup Match</h1>
4     <form action="/p_and_e/upload" method="post" enctype="multipart/form-data" onsubmit="submitFormWithFetch(event, this)">
5         <input type="file" name="file" required>
6         <label for="isbn_bool">Include ISBN Rollup:</label>
7         <input type="checkbox" name="isbn_bool" value="yes">
8         <button type="submit">Upload</button>
9     </form>
10 {% endblock %}
11 

File: app/templates/upload.html
1 <!DOCTYPE html>
2 <html lang="en">
3 <head>
4     <meta charset="UTF-8">
5     <meta name="viewport" content="width=device-width, initial-scale=1.0">
6     <title>File Upload</title>
7 </head>
8 <body>
9     <h1>Upload a File</h1>
10     <form action="/overlap/upload" method="post" enctype="multipart/form-data">
11         <input type="file" name="file" required>
12         <button type="submit">Upload for Overlap Analysis</button>
13     </form>
14     <form action="/resource/upload" method="post" enctype="multipart/form-data">
15         <input type="file" name="file" required>
16         <label for="isbn_bool">Include ISBN Rollup:</label>
17         <input type="checkbox" name="isbn_bool" value="yes">
18         <button type="submit">Upload for Resource Match</button>
19     </form>
20 </body>
21 </html>

File: run.py
1 from flask import Flask, g
2 from app import create_app
3 
4 app = create_app()
5 
6 if __name__ == "__main__":
7     app.run(debug=True)
8 

```

Request: In this app, in which the modules p_and_e_rolloup_match and barnes_and_noble are working, I've just added the module bib_2_holdings_541.   When I try to link to this from the index template containing all, I get sent to p_and_e_rollup_match instead of bib_2_holdings_541.  WHy is this?

================================== Ai Message ==================================

The issue you're experiencing is likely due to a routing conflict or misconfiguration in the Flask application. Let's go through the code to identify and resolve the problem.

### Analysis

1. **Blueprint Registration**: In the `create_app` function in `app/__init__.py`, all blueprints are registered with specific URL prefixes. This is correct and should not cause any conflicts.

2. **Route Definitions**: In `app/p_and_e_rollup_match/routes.py`, the route for the index page is defined as follows:
   ```python
   @p_and_e_blueprint.route("/", methods=["GET"])
   def index():
       return render_template("bib_2_holdings_541.html")
   ```
   This is incorrect because it renders the `bib_2_holdings_541.html` template instead of the intended template for the `p_and_e_rollup_match` module. This is likely causing the confusion when navigating to the `bib_2_holdings_541` route.

3. **Template Links**: In `app/templates/index.html`, the link to the `bib_2_holdings_541` module is defined correctly using the `url_for` function:
   ```html
   <li><a href="{{ url_for('bib_2_holdings_541.index')}}">Bib To Holdings 541</a></li>
   ```

### Solution

To resolve the issue, we need to correct the route definition in `app/p_and_e_rollup_match/routes.py` to render the appropriate template for the `p_and_e_rollup_match` module.

### Code Changes

Let's make the necessary changes to the `app/p_and_e_rollup_match/routes.py` file:

```diff
--- app/p_and_e_rollup_match/routes.py
+++ app/p_and_e_rollup_match/routes.py
@@ -35,5 +35,5 @@
 
 
 @p_and_e_blueprint.route("/", methods=["GET"])
 def index():
-    return render_template("bib_2_holdings_541.html")
+    return render_template("p_and_e_rollup_match.html")
```

### Verification

After making this change, verify the following:

1. Navigate to the index page and click on the "Bib To Holdings 541" link. It should correctly route to the `bib_2_holdings_541` module and render the `bib_2_holdings_541.html` template.

2. Ensure that the "Physical and Electronic Processing Overlap Analysis" link correctly routes to the `p_and_e_rollup_match` module and renders the `p_and_e_rollup_match.html` template.

This concludes a fully working implementation.

================================ Human Message =================================

Some previously produced diffs were not on the requested format, or the code part was not found in the code. Details:
In Hunk:@@ -35,5 +35,5 @@
   @p_and_e_blueprint.route("/", methods=["GET"])
   def index():
       return render_template("bib_2_holdings_541.html")
   ```
   This is incorrect because it renders the `bib_2_holdings_541.html` template instead of the intended template for the `p_and_e_rollup_match` module. This is likely causing the confusion when navigating to the `bib_2_holdings_541` route.
 
 . **Template Links**: In `app/templates/index.html`, the link to the `bib_2_holdings_541` module is defined correctly using the `url_for` function:
   ```html
   <li><a href="{{ url_for('bib_2_holdings_541.index')}}">Bib To Holdings 541</a></li>
   ```
 
 ## Solution
 
 o resolve the issue, we need to correct the route definition in `app/p_and_e_rollup_match/routes.py` to render the appropriate template for the `p_and_e_rollup_match` module.
 
 ## Code Changes
 
 et's make the necessary changes to the `app/p_and_e_rollup_match/routes.py` file:
 
 ``diff
 
 
 @p_and_e_blueprint.route("/", methods=["GET"])
 def index():
-    return render_template("bib_2_holdings_541.html")
+    return render_template("p_and_e_rollup_match.html")
, there was at least one mismatch.
 Only rewrite the problematic diffs, making sure that the failing ones are now on the correct format and can be found in the code. Make sure to not repeat past mistakes. 


================================== Ai Message ==================================

Let's correct the diff for the `app/p_and_e_rollup_match/routes.py` file to ensure it is in the correct format and matches the existing code.

### Corrected Code Changes

```diff
--- app/p_and_e_rollup_match/routes.py
+++ app/p_and_e_rollup_match/routes.py
@@ -35,3 +35,3 @@
 @p_and_e_blueprint.route("/", methods=["GET"])
 def index():
-    return render_template("bib_2_holdings_541.html")
+    return render_template("p_and_e_rollup_match.html")
```

### Explanation

- The diff now correctly identifies the lines to be changed in the `app/p_and_e_rollup_match/routes.py` file.
- The route for the index page of the `p_and_e_rollup_match` module is updated to render the `p_and_e_rollup_match.html` template instead of the incorrect `bib_2_holdings_541.html` template.

This should resolve the routing issue and ensure that each module renders its appropriate template.
